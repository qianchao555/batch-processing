## MySql

### MySQL体系结构

![MySQL体系结构图](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/5-200622094009461.png)

上图为MySQL基础架构图

MySQL由连接池、SQL接口、解析器、优化器、缓存、存储引擎等组成。可以分为三层：MySQL Server层、存储引擎层、文件系统层。MySQL Server层又包括连接层和SQL层

Connectors不属于以上任何一层，可以将Connectors理解为各种客户端、应用服务，主要是指不同语言与MySQL的交互

#### MySQL Server

##### 连接层

1. 应用程序通过接口(JDBC、ODBC等等)来连接MySQL，最先处理的是连接层。连接层包括通信协议、线程处理、用户密码认证3部分
   - 通信协议负责检测客户端版本是否兼容 MySQL 服务端
   - 线程处理是指每一个连接请求都会分配一个对应的线程，相当于一条 SQL 对应一个线程，一个线程对应一个逻辑 CPU，在多个逻辑 CPU 之间进行切换
   - 密码认证用来验证用户创建的账号、密码，以及 host 主机授权是否可以连接到 MySQL 服务器
2. 连接池（Connection Pool）属于连接层。由于每次建立连接都需要消耗很多时间，连接池的作用就是将用户连接、用户名、密码、权限校验、线程处理等需要缓存的需求缓存下来，下次可以直接用已经建立好的连接，提升服务器性能

##### SQL层

SQL层是MySQL的核心，核心服务都在这一层实现。主要包括权限判断、查询缓存、解析器、预处理、查询优化器、缓存、执行计划

1. 权限判断可以审核用户有没有访问某个库、某个表，或者表里某行数据的权限
2. 查询缓存通过 Query Cache 进行操作，如果数据在 Query Cache 中，则直接返回结果给客户端，不必再进行查询解析、优化和执行等过程
3. 查询解析器针对 SQL 语句进行解析，判断语法是否正确
4. 预处理器对解析器无法解析的语义进行处理
5. 查询优化器对 SQL 进行改写和相应的优化，并生成最优的执行计划，就可以调用程序的 API 接口，通过存储引擎层访问数据

Management Services & Utilities、SQL Interface、Parser、Optimizer 和 Caches & Buffers 属于 SQL 层，详细说明如下表所示。

| 名称                            | 说明                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| Management Services & Utilities | MySQL 的系统管理和控制工具，包括备份恢复、MySQL 复制、集群等。 |
| SQL Interface（SQL 接口）       | 用来接收用户的 SQL 命令，返回用户需要查询的结果。例如 SELECT FROM 就是调用 SQL Interface。 |
| Parser（查询解析器）            | 在 SQL 命令传递到解析器的时候会被解析器验证和解析，以便 MySQL 优化器可以识别的数据结构或返回 SQL 语句的错误。 |
| Optimizer（查询优化器）         | SQL 语句在查询之前会使用查询优化器对查询进行优化，同时验证用户是否有权限进行查询，缓存中是否有可用的最新数据。它使用“选取-投影-连接”策略进行查询。例如 `SELECT id, name FROM student WHERE gender = "女";`语句中，SELECT 查询先根据 WHERE 语句进行选取，而不是将表全部查询出来以后再进行 gender 过滤。SELECT 查询先根据 id 和 name 进行属性投影，而不是将属性全部取出以后再进行过滤，将这两个查询条件连接起来生成最终查询结果。 |
| Caches & Buffers（查询缓存）    | 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的，比如表缓存、记录缓存、key 缓存、权限缓存等。 |



#### 存储引擎层

1. 存储引擎层是 MySQL 数据库区别于其他数据库最核心的一点，也是 MySQL 最具特色的一个地方。主要负责 MySQL 中数据的存储和提取
2. 因为在关系数据库中，数据的存储是以表的形式存储的，所以存储引擎也可以称为表类型（即存储和操作此表的类型）

#### 文件系统层

1. 文件系统层主要是将数据库的数据存储在操作系统的文件系统之上，并完成与存储引擎的交互

-------------------------------------------------------------------------------------

### mysql数据类型

MySQL数据类型大致分为5类，整数类型、浮点数类型和定点数类型、日期和时间类型、字符串类型、二进制类型

#### 整数类型

| 类型名称  | 说明           | 存储需求 |
| --------- | -------------- | -------- |
| tinyInt   | 很小的整数     | 1个字节  |
| smallInt  | 小的整数       | 2个字节  |
| MediumInt | 中等大小的整数 | 3个字节  |
| Int       | 普通大小的整数 | 4个字节  |
| bigInt    | 大整数         | 8个字节  |

#### 浮点数类型\定点数

| 类型名称          | 说明               | 存储需求   |
| ----------------- | ------------------ | ---------- |
| float             | 单精度浮点数       | 4 个字节   |
| double            | 双精度浮点数       | 8个字节    |
| decimal(M,D)，dec | 压缩的“严格”定点数 | M+2 个字节 |

1. double 实际上是以字符串的形式存放的，decimal 可能的最大取值范围与 DOUBLE 相同，但是有效的取值范围由 M 和 D 决定。如果改变 M 而固定 D，则取值范围将随 M 的变大而变大。
2. 从上表中可以看到，DECIMAL 的存储空间并不是固定的，而由精度值 M 决定，占用 M+2 个字节。  

#### 日期/时间类型

| 类型名称  | 日期格式            | 日期范围                                          | 存储需求 |
| --------- | ------------------- | ------------------------------------------------- | -------- |
| year      | YYYY                | 1901 ~ 2155                                       | 1 个字节 |
| time      | HH:MM:SS            | -838:59:59 ~ 838:59:59                            | 3 个字节 |
| date      | YYYY-MM-DD          | 1000-01-01 ~ 9999-12-3                            | 3 个字节 |
| dateTime  | YYYY-MM-DD HH:MM:SS | 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59         | 8 个字节 |
| timeStamp | YYYY-MM-DD HH:MM:SS | 1980-01-01 00:00:01 UTC ~ 2040-01-19 03:14:07 UTC | 4 个字节 |



#### 字符串类型

char、varchar、tinyText、text、mediumText、longText、enmu、set

#### 二进制类型

bit、binary、varBinary、tinyBlob、blob、mediumBlob、longBlob

---

### 数据库范式

构造数据库必须遵循一定的规则，在关系数据库中，这种规则就是范式。关系数据库中的关系必须满足一定的要求，即满足不同的范式

1NF：属性不可分，即：数据库表的每一列都是不可再分割的基本数据项

2NF：符合1NF，并且每一个非主属性完全依赖于码(候选码、主码都称为码)。即：要求数据库表中的每个实例或行必须可以被唯一区分。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。这个唯一属性列被称为主键

要求

- 满足1NF
- 表必须有一个主键
- 对于没有包含主键的列(非主键的其他列)必须完全依赖于全部主键，而不能依赖于主键的一部分(部分主键)

3NF：非主属性既不传递依赖于码，也不部分依赖于码。3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。像：a-->b-->c  属性之间含有这样的关系，是不符合3NF的。

3NF：在1NF基础上，除了主键以外的其它列都不传递依赖于主键列，或者说： 任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）

要求

- 满足2NF
- 非主键列必须直接依赖于主键，不能存储在传递依赖。即：不能存在非主键列A依赖于非主键列B，非主键B依赖于主键的情况



---



### 优化SQL

#### 索引失效情况

1. like以%开头的索引会失效，name like 'qqcc%'索引有效
2. 组合索引，应按照最左匹配原则，若使用的不是第一列索引时，则索引失效
3. 索引列上使用 Is null，Is not null时，索引失效，因为索引不会索引空值
4. 索引字段上使用：not、<>、!=、不会走索引，而是全表扫描
5. 索引字段上计算、运用函数不会使用索引
6. or语句前后没有同时使用索引

---



### MySQL事务

#### 事务四大特性ACID

1. 原子性(Atomicity):一个事务中的所有操作，要么全部完成，要么全部不完成。事务在执行过程中发生错误会被回滚到事务开始前的状态，就像这个事务没有执行过一样
   - undo log实现
   - 每条数据变更（INSERT/UPDATE/DELETE/REPLACE）等操作都会生成一条undolog记录，在SQL执行前先于数据持久化到磁盘
   - 当事务需要回滚时，MySQL会根据回滚日志对事务中已执行的SQL做逆向操作，比如 DELETE 掉一行数据的逆向操作就是再把这行数据 INSERT回去，其他操作同理
2. 一致性(Consistency):事务开始之前和事务结束之后，数据库的完整性没有被破坏。
   - 通过原子性、隔离性、持久性最终实现数据一致性
3. 隔离性(Isolation):数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致
   - 读写锁+Mvcc实现
4. 持久性(Durability):事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失
   - binlog、redo log实现

#### 并发事务处理带来的问题

##### 脏读

一个事务读取到另一个事务未提交的数据。当前事务正在访问数据并且进行了修改，但是这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个修改的数据

![image-20220325165637236](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220325165637236.png)

##### 不可重复读

一个事务对同一行数据重复读取两次，但得到的结果不同

一个事务内，多次读取同一数据。在这个事务还没有结束时，另外一个事务也访问同一数据。那么在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读

![image-20220325165624391](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220325165624391.png)

##### 幻读

一个事务执行两次查询，但第二次查询的结果包含了第一次查询中未出现的数据。

例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。

![image-20220325165605236](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220325165605236.png)

##### 丢失更新

两个事务同时更新一行数据，后提交(或撤销)的事务将之前事务提交的数据覆盖了

###### 第一类丢失更新

指两个事务同时操作同一个数据时，当第一个事务撤销时，把已经提交的第二个事务的更新数据覆盖了，第二个事务就造成了数据丢失

###### 第二类丢失更新

指两个事务同时操作同一个数据时，第一个事务将修改结果成功提交后，对第二个事务已经提交的修改结果进行了覆盖，对第二个事务造成了数据丢失

![image-20220325171513602](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220325171513602.png)

###### 如何避免丢失更新的发生

- 锁机制防止丢失更新

- 行级排它锁解决

  

为了解决上述事务并发问题的出现，SQL规范中定义了四种隔离级别，不同隔离级别对事务的处理有所不同





#### 事务的隔离级别

作用：让并发的事务相互隔离，互不影响，这样可以保证事务的一致性

1. 读未提交：事务AB，对于B来说，事务A未提交的变更数据，事务B可以读取到
2. 读已提交：事务AB，A事务提交之后的数据，当前B事务才能读取其他事务做的变更。Oracle默认隔离级别
3. 可重复读：事务AB，事务A提交之后的数据，事务B读取不到。一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。(mvcc实现的又叫快照读)
   当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的
4. 串行化：事务AB，mysql在同一时刻只允许单个事务执行，事务A在操作数据库时，事务B只能排队等待

| 隔离级别类型             | 脏读 | 不可重复读 | 幻读 |
| ------------------------ | ---- | ---------- | ---- |
| 读未提交Read uncommitted | 会   | 会         | 会   |
| 读已提交read committed   | 不会 | 会         | 会   |
| 可重复读 repeatable read | 不会 | 不会       | 会   |
| 序列化Serializable       | 不会 | 不会       | 不会 |

#### 如何解决这些问题

##### 锁机制

数据库通过锁机制解决并发访问的问题，MySQL事务隔离依靠锁来实现的，加锁自然会带来性能的损失。但是读未提交隔离级别是不加锁的，所有他的性能最好。但是会造成连脏读都没有办法解决

1. 根据锁对象不同分为：
   - 行级锁：锁定当前数据行，锁的粒度小、加锁慢，发生锁冲突概率小，并发度高。InnoDB支持行锁和事务、MyISAM这两者都不支持
   - 为了更改数据，数据库必须在进行更改的行上施加独占锁，insert、update、delete、select for update语句会隐式的采用行锁定
   - 表级锁：锁的粒度大，加锁快，开销小，但是锁冲突的概率大，并发度低
2. 根据并发事务锁定的关系上看：
   - 共享锁：针对同一份数据，多个读操作可以同时进行，但是不能写操作
   - 独占锁：针对写操作，假如当前写操作没有完成，那么它会阻断其他的写锁和读锁，即：写加锁，其他读写都阻塞

为什么上了写锁，别的事务还可以读操作？==》MVCC机制，使用快照读，不会被阻塞

读未提交加锁情况：没加锁

串行化加锁情况：读的时候加的共享锁，也就是其他事务可以并发读取，但是不能写。写的时候加的排它锁(写锁、独占锁、X锁)，其他事务不能并发读和写

读已提交加锁情况：他们俩的底层实现采用的是MVCC（多版本并发控制）方式进行实现

可重复读加锁情况：他们俩的底层实现采用的是MVCC（多版本并发控制）方式进行实现

#### Innodb如何解决幻读

MySQL存储引擎InnoDB在可重复的隔离级别下，是解决了幻读问题的

解决方法：通过临键锁(next-key lock)在当前事务开启时，首先给涉及到的行加锁防止写操作，其次通过给涉及到的行两端加间隙锁(Gap lock)防止新增行写入；从而解决了幻读问题

~~~sql
mysql> select * from LOL;
+----+--------------+--------------+-------+
| id | hero_title   | hero_name    | price |
+----+--------------+--------------+-------+
|  1 | 刀锋之影     | 泰隆         |  6300 |
|  2 | 迅捷斥候     | 提莫         |  6300 |
|  3 | 光辉女郎     | 拉克丝       |  1350 |
|  4 | 发条魔灵     | 奥莉安娜     |  6300 |
|  5 | 至高之拳     | 李青         |  6300 |
|  6 | 无极剑圣     | 易           |   450 |
|  7 | 疾风剑豪     | 亚索         |  6300 |
+----+--------------+--------------+-------+
7 rows in set (0.00 sec)
~~~



![image-20220325134120755](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220325134120755.png)

1. Q1 只返回 "无极剑圣" 这一行；
2. 在 T2 时刻，session B 把 "疾风剑豪" 这一行的 price 值改成了 450，因此 T3 时刻 Q2 查出来的是 "无极剑圣" 和 "疾风剑豪" 这两行；
3. 在 T4 时刻，session C 又插入一行 (10,'雪人骑士','努努','450')，因此 T5 时刻 Q3 查出来 price = 450 的是"无极剑圣" 、"疾风剑豪" 和 "雪人骑士" 这三行。

其中，Q3 读到 (10,'雪人骑士',450) 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行

原理

那么幻读能仅通过行锁解决么？

答案是否定的。如上面示例，`select xx for update（当前读）`是将所有条件涉及到的（符合where条件）行加上行锁。但是，就算在select xx for update 事务开启时将所有的行都加上行锁，也锁不住Session C新增的行，因为在我给数据加锁的时刻，压根就还没有新增的那行，自然也不会给新增行加上锁

所以要解决幻读，必须得解决新增行的问题！

产生幻读的原因是：行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)

比如表 LOL，初始化插入了 7 个记录，这就产生了 8 个间隙。

![image-20220325135414075](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220325135414075.png)



next-key lock

当执行 select * from LOL where hero_title = '疾风剑豪' for update 的时候，就不止是给数据库中已有的 7 个记录加上了行锁，还同时加了 8 个间隙锁。这样就确保了无法再插入新的记录，也就是Session C在T4新增(10,'雪人骑士','努努','450') 行时，由于ID大于7，被间隙锁（7，+∞）锁住。

  在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。MySQL将行锁 + 间隙锁组合统称为 next-key lock，通过 next-key lock 解决了幻读问题。

**作用**：

- 防止间隙中执行insert
- 防止将已有数据update到间隙中

**注意：**  next-key lock的确是解决了幻读问题，但是next-key lock在并发情况下也经常会造成死锁。死锁检测和处理也会花费时间，一定程度上影响到并发量



---



### MySQL存储引擎与表类型

#### 表类型

1. 表类型由存储引擎决定，主要包括MyISAM、InnoDB、Memory、Csv、archive、mrg_myisam
2. 这类又分为：事务安全型（InnoDB）、非事务安全型(其余都是)

#### 存储引擎

搞懂前两个即可

##### InnoDB

- 5.7及以后默认存储引擎	
- 优点：支持事务和崩溃修复能力；引入了行锁和外键约束
- 适用于事务支持，并且有较高的并发读写频率

##### MyISAM

- 5.5以前版本默认存储引擎
- 对于只读数据、或表比较小、可以容忍修复操作等可以使用MyISAM存储引擎
- MyISAM会将表存储在两个文件中：数据文件.myd 和索引文件 .myi

##### Memory

- Memory存储引擎将数据全部放在内存中，访问速度快，但是一旦系统崩溃，数据全部丢失
- 默认使用哈希索引，将键的哈希值和指向数据行的指针保存在哈希索引中

##### InnoDB/MyISAM两者区别

1. InnoDB支持行锁和表锁、默认是行锁，MyISAM只支持表锁
2. InnoDB支持事务，MyISAM不支持事务
3. InnoDB支持外键，MyISAM不支持
4. InnoDB支持MVCC，MyISAM不支持。应对高并发事务，MVCC比单纯的加锁更高效
5. InnoDB支持聚集索引，MyISAM不支持聚集索引

---



### MVCC实现原理

https://www.php.cn/mysql-tutorials-460111.html

MVCC：Multiversion concurrency control 多版本并发控制，主要是为了提高数据库并发性能，对于高并发场景，MVCC比行级锁开销更小

MVCC是维持一个数据的多个版本，使读写操作没有冲突的一个抽象概念，具体实现就是快照读

就是同一份数据保留多版本的一种方式，进而实现并发控制。在查询的时候，通过read view和版本链找到对应版本的数据



#### 数据库并发场景

1. 读-读：不存在任何问题，也不需要并发控制
2. 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
3. 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

#### MVCC解决哪些并发问题

mvcc用来解决读—写冲突的无锁并发控制，就是为事务分配单向增长的时间戳。为每个数据修改保存一个版本，版本与事务时间戳相关联。

1. 并发 读-写时：可以做到读操作不阻塞写操作，写操作不阻塞读操作
2. 解决脏读、幻读、不可重复读等事务隔离问题
3. 但是不能解决写-写 更新丢失问题

因此出现了提高并发性能的组合：

MVCC+悲观锁：mvcc解决读写冲突，悲观锁解决写写冲突

MVCC+乐观锁mvcc解决读写冲突，乐观锁解决写写冲突



#### 实现原理

MVCC依赖于版本链、undo log、read view来实现

数据库中的每行数据，除了肉眼可见的数据，还有几个隐藏字段。版本链是通过表的三个隐藏字段实现

1. DB_TRX_ID：当前操作该记录的事务id，通过事务id的大小判断事务的时间顺序
2. DB_ROLL_PRT：(pointer) 回滚指针，指向当前行记录的上一个版本，通过这个指针将数据的多个版本连接在一起构成undo log版本链
3. DB_ROW_ID：主键，如果数据表没有主键，Innodb会自动以db_row_id产生一个聚集索引

每条记录大概是这样的

| name | age  | DB_ROW_ID | DB_TRX_ID | DB_ROLL_PTR |
| ---- | ---- | --------- | --------- | ----------- |
| YHC  | 25   | 1         | 1         | 0x23333     |

​	

##### 版本链

使用事务更新行记录的时候，就会生成版本链，执行过程：

1. 用排他锁锁住该行
2. 将该行原本的值拷贝到undo log，作为旧版本用于回滚
3. 修改当前行的值，生成一个新的版本，更新事务id，使 回滚指针指向旧版本记录，这一就形成一条版本链

![image-20220324133558317](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220324133558317.png)

例如：

初始数据如下，其中DB_TRX_ID和DB_POLL_PTR为null

| name | age  | DB_ROW_ID | DB_TRX_ID | DB_ROLL_PTR |
| ---- | ---- | --------- | --------- | ----------- |
| YHC  | 25   | 1         | null      | null        |

事务A对该行做了修改，将age改为30

| name | age  | DB_ROW_ID | DB_TRX_ID | DB_ROLL_PTR |
| ---- | ---- | --------- | --------- | ----------- |
| YHC  | 30   | 1         | 1         | 0x100000    |

此时undo log																																										 $\downarrow$

| name | age  | DB_ROW_ID | DB_TRX_ID | DB_ROLL_PTR |
| ---- | ---- | --------- | --------- | ----------- |
| YHC  | 30   | 1         | null      | null        |

之后事务B也对该记录做了修改，将age改为8

| name | age  | DB_ROW_ID | DB_TRX_ID | DB_ROLL_PTR |
| ---- | ---- | --------- | --------- | ----------- |
| YHC  | 8    | 1         | 2         | 0x23333     |

​																																															 $\downarrow$  回滚指针

此时undo log有两行记录，并且通过回滚指针连在一起

| name | age  | DB_ROW_ID | DB_TRX_ID | DB_ROLL_PTR                                        |
| ---- | ---- | --------- | --------- | -------------------------------------------------- |
| YHC  | 30   | 1         | 1         | 0x100000   	 $\downarrow$  通过回滚指针连在一起 |
| YHC  | 25   | 1         | null      | null                                               |



##### undo log

1. 主要用于记录数据被修改之前的日志，在表信息修改之前会把数据拷贝到undo log中
2. 保证事务进行rollback时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复
3. 用于mvcc快照读的数据，在mvcc多版本并发控制中，通过读取undo log的历史版本数据，可以实现不同事务版本号都拥有自己独立的快照数据版本

##### read view(读视图)

read view实现快照读，可以理解为将数据在每个时刻的状态拍成照片记录下来。在获取某个时刻 t 的数据时，到 t 时间点拍的照片上取出数据

事务进行快照读操作的时候产生读视图(read view)，在该事务执行的快照读那一刻，会生成数据库系统当前的一个快照

read view记录并维护系统中当前活跃事务的ID（没有commit，当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以越新的事务，ID值越大)，通过这个列表来判断记录的某个版本是否对当前事务可见

读视图的作用：主要用来做可见性判断，当某个事务执行快照读的时候，对该记录创建一个reda view，把它比作条件用来判断当前事务能够看到哪个版本的数据，即：可能是当前最新的数据，也可能是该行记录的undo log里面的某个版本的数据

###### read view几个属性

1. trx_ids：当前系统活跃(未提交)事务版本号集合
2. low_limit_id：创建当前read view时，当前系统最大事务版本号+1
3. up_limit_id：创建当前read view时，系统正处于活跃事务最小版本号
4. creator_trx_id：创建当前read view的事务版本号

###### read view可见性判断条件



1. 显示：db_trx_id<up_limit_id || db_trx_id == creator_trx_id 
   - 如果当前事务ID小于read view中最小活跃事务ID，则可以肯定该数据是在当前事务开启之前就已经存在了，所有可以显示
   - 或者当前事务ID等于creator_trx_id，那么说明这个数据就是当前事务自己生成的，自己生成当然可见
2. 不显示：db_trx_id>=low_limit_id
   - 当前事务ID，大于read view中当前系统的最大事务Id，则说明该数据是当前read view创建之后产生的，所以不显示。如果小于则进入下一个判断
3. db_trx_id是否在活跃事务(trx_ids)中
   - 不在：则说明read view产生的时候，事务已经commit了，这种情况则可以显示
   - 存在：说明 我read view生成时刻，你这个事务还在活跃，还没有commit，你修改的数据，我当前事务看不见的



#### 总结

InnoDB的MVCC通过read view 和版本链实现，版本链保存有历史版本记录，通过read view 判断当前版本的数据是否可见，如果不可见，再从版本链中找到上一个版本，继续进行判断，直到找到一个可见的版本

---



### MySQL分库分表

#### 水平切分

1. 水平切分又叫：Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。
2. 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力。
3. ![image-20220315211326794](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152113604.png)

#### 垂直切分

1. 垂直切分是将一张表切分成多个表，通常按照列的关系密集程度进行切分，也可以将经常使用的列和不经常使用的列切分到不同的表中
2. 在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等
3. ![image-20220315211420628](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152114120.png)

#### Sharding策略

1. 哈希取模：hash(key)%Num_Db
2. 范围:可以是ID范围，也可以是时间范围
3. 映射表：使用单独的一个数据库来存储映射关系

---



### MySQL分区

参考：

https://www.cnblogs.com/helios-fz/p/13671682.html

https://juejin.cn/post/6844903991944413191

#### 概念

1. 将同一表中，不同行的记录分配到不同的物理文件中，几个分区就有几个.ibd文件(InnoDB引擎)。（MyISAM引擎生成.myd 和.myi文件）
2. 分区是将一个表或索引分解成多个更小、更可管理的部分。每个分区都是独立的，可以独立处理，亦可以作为一个更大对象的一部分进行处理
3. MySQL数据库的分区是局部分区索引，一个分区中既存了数据，又放了索引，也就是说，每个区的聚集索引和非聚集索引都放在各自区的(不同的物理文件)。目前MySQL不支持全局分区

#### 分区类型

以下几种：无论哪种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分

查看执行计划，和普通的执行计划比较多了partitions、filtered字段，partitions标识走了哪几个分区

explain partitions select 语句；

##### Range分区

1. 是实战中最为常用的一种分区类型，行数据基于属于一个给定的连续区间的列值被放入分区。但是，当插入的数据不再一个分区中定义的值的时候，会抛异常

2. ~~~mysql
   CREATE TABLE `m_test_db`.`Order` (
       `id` INT NOT NULL AUTO_INCREMENT,
       `partition_key` INT NOT NULL,
       `amt` DECIMAL(5) NULL,
       PRIMARY KEY (`id` , `partition_key`)
   ) PARTITION BY RANGE (partition_key) PARTITIONS 5 (
   PARTITION part0 VALUES LESS THAN (201901) , 
   PARTITION part1 VALUES LESS THAN (201902) , 
   PARTITION part2 VALUES LESS THAN (201903) , 
   PARTITION part3 VALUES LESS THAN (201904) , 
   PARTITION part4 VALUES LESS THAN (201905));
   #插入数据
   INSERT INTO `m_test_db`.`Order` (`id`, `partition_key`, `amt`) VALUES ('1', '201901', '1000');
   INSERT INTO `m_test_db`.`Order` (`id`, `partition_key`, `amt`) VALUES ('2', '201902', '800');
   INSERT INTO `m_test_db`.`Order` (`id`, `partition_key`, `amt`) VALUES ('3', '201903', '1200');
   
   ~~~

   - ~~~mysql
     explain partitions select * from order where partition_key ='201902'
     #可以看出，SQL优化器只搜索对应的part2分区
     ~~~

   - |      |             |       |            |       |               |      |         |      |      |          |       |
     | ---- | ----------- | ----- | ---------- | ----- | ------------- | ---- | ------- | ---- | ---- | -------- | ----- |
     | id   | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
     | 1    | Simple      | order | part2      | index |               |      |         |      |      |          |       |

注意事项：

1. MySQL分区表如果有主键，那么必须包含分区字段，所以创建语句是一个复合主键，否则会报SQL创建表错误
2. 对于原生分区，分区对象返回的只能是整数值
3. 分区字段不能为null

以下几种分区不常用：

##### List分区

LIST分区和RANGE分区很相似，只是分区列的值是离散的，不是连续的。LIST分区使用VALUES IN，因为每个分区的值是离散的，因此只能定义值

##### Hash分区

将数据均匀的分布到预先定义的各个分区中，以保证每个分区的熟练大致相同

##### Key分区

KEY分区和HASH分区相似，不同之处在于HASH分区使用用户定义的函数进行分区，KEY分区使用数据库提供的函数进行分区

##### 子分区

##### MySQL分区处理Null值的方式

#### 分区管理

#### 分区和性能

分区主要用于数据库高可用性的管理

---

### MySQL备份

#### 备份分类

##### 物理备份文件

物理备份：对数据库操作系统的物理文件(如：数据文件、日志文件)

冷备份(脱机备份)：关闭数据库的时候进行的

热备份(联机备份)：数据库处于运行状态，依赖于数据库的日志文件

温备份：数据库锁定表格(不可写入但可读)的状态下进行备份操作

##### 逻辑备份

#### 常用备份方法

1. 物理备份
2. 专用备份工具
   - mysqldump:常用
   - mysqlhotcopy：仅拥有备份MyISAM和Archive表类型
3. 启动二进制日志进行增量备份
   - 进行增量备份，需要刷新二进制日志
4. 第三方工具备份
   - MySQL免费热备份软件 Percona XtraBackUp



#### 完全备份

对整个数据库进行备份、数据库结构和文件结构的备份



---



### MySQL一条SQL的执行过程详解

#### MySQL驱动

1. 系统和MySQL数据库进行交互前，MySQL驱动会帮我们建立连接。一次SQL请求就会建立一个连接，多个请求就会建立多个连接。由于性能原因，引入数据库连接池

2. ![image-20220315211512773](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152115509.png)

   

3. 数据库连接池

   - 维护一定的连接数，方便系统获取连接，使用时从池子中获取，用完之后放回去就可以了。我们不用关系连接的创建和销毁，因为不必关心线程池是怎么去维护这些连接的
   - 常见的数据库连接池Druid、C3P0、DBCP
   - 好处：大大节省了不断创建和销毁连接而带来的性能开销
   - ![image-20220315211611686](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152116696.png)

   

#### 数据库连接池

1. MySQL架构提供了数据库连接池，双方都是通过数据库连接池来管理各个连接的，这样一方面线程之前不需要是争抢连接，更重要的是不需要反复的创建的销毁连接
2. ![image-20220315211635997](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152116888.png)

#### 网络连接必须由线程来处理

1. 所谓网络连接，说白了就是一次请求，每次请求都会有相应的线程去处理。对于 SQL 语句的请求在 MySQL 中是由一个个的线程去处理的
2. ![image-20220315211657924](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152117993.png)

#### SQL接口

MySQL中处理请求的线程在获取到请求以后，获取的SQL语句交给SQL接口去处理

#### 查询解析器

~~~sql
--例如：以下SQL
select studentName from students where id=1;
~~~

1. 解析器将SQL接口传递过来的SQL语句进行解析，翻译成MySQL数据库自己能认识的语言
2. ![image-20220315211758377](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152117498.png)
3. 现在请求的SQL语句已经解析为MySQL数据库能认识的样子了，下一步MySQL会按照自己任务效率最高的方式去执行SQL语句

#### MySQL查询优化器

1. MySQL会为我们生成一条条的执行计划。比如你创建了多个索引等等
2. 优化器选出最优索引等步骤后，由执行器去调用存储引擎接口，开始去执行被MySQL解析过和优化过的SQL语句
3. ![image-20220315211814567](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152118692.png)

#### 执行器

1. 执行器是一个非常重要的组件，因为前面那些组件的操作最终必须通过执行器去调用存储引擎接口才能被执行。执行器最终会根据一系列的执行计划去调用存储引擎的接口去完成 SQL 的执行
2. ![image-20220315211830067](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152118217.png)

#### 存储引擎

查询优化器会调用存储引擎的接口，去执行 SQL，也就是说真正执行 SQL 的动作是在存储引擎中完成的。数据是被存放在内存或者是磁盘中的（存储引擎是一个非常重要的组件，后面会详细介绍

#### 初识存储引擎

~~~mysql
#以更新sql举例
update students set studentName='小强' where id=1；
~~~

1. 当Java系统发出这样的查询交给MySQL时，它会按照上面的一系列流程最终通过执行器调用存储引擎去执行
2. 执行这个sql时候，sql对应的数据要么在内存中、要么在磁盘上，如果直接在磁盘中操作，那么随机IO的读写速度肯定是很慢的，所以每次执行SQL的时候，都会将数据加载到内存中，这块内存就是InnoDB中一个非常重要的组件：缓存池（Buffer Pool）

##### Buffer Pool

1. 顾名思义，缓冲池其实就是类似  Redis  一样的作用，起到一个缓存的作用，因为我们都知道 MySQL 的数据最终是存储在磁盘中的，如果没有这个 Buffer Pool  那么我们每次的数据库请求都会磁盘中查找，这样必然会存在 IO 操作，这肯定是无法接受的
2. 有了 Buffer Pool 就是我们第一次在查询的时候会将查询的结果存到  Buffer Pool 中，这样后面再有请求的时候就会先从缓冲池中去查询，如果没有再去磁盘中查找，然后在放到  Buffer Pool 中，如下：
3. ![image-20220315211848501](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152118602.png)
4. 此条SQL执行步骤大致如下：
   - innodb 存储引擎会在缓冲池中查找 id=1 的这条数据是否存在
   - 发现不存在，那么就会去磁盘中加载，并将其存放在缓冲池中
   - 该条记录会被加上一个独占锁（总不能你在修改的时候别人也在修改吧，这个机制本篇文章不重点介绍，以后会专门写文章来详细讲解）

##### undo日志文件：记录数据被修改前的样子

undo log 就是没有发生事情的一些日志

1. 在将SQL查询到的数据加载到Buffer Pool时，同时会往undo日志文件插入一条日志，也就是将id=1这条记录的原来的值记录下来
2. 这样做的目的？
3. Innodb 存储引擎的最大特点就是支持事务，如果本次更新失败，也就是事务提交失败，那么该事务中的所有的操作都必须回滚到执行前的样子，也就是说当事务失败的时候，也不会对原始数据有影响
4. ![image-20220315211906526](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152119619.png)
5. 到这一步，我们的执行的 SQL 语句已经被加载到 Buffer Pool 中了，然后开始更新这条语句，更新的操作实际是在Buffer Pool中执行的，此时就会造成Buffer Pool和数据库中的数据不一致问题

##### redo日志文件：记录数据被修改后的样子

1. 除了从磁盘中加载文件和将操作前的记录保存到 undo 日志文件中，其他的操作是在内存中完成的，内存中的数据的特点就是：断电丢失。如果此时 MySQL 所在的服务器宕机了，那么 Buffer Pool 中的数据会全部丢失的。这个时候 redo 日志文件就需要来大显神通了
2. redo日志文件是InnoDB特有的，它是存储引擎级别的，不是MySQL级别的
3. redo 记录的是数据修改之后的值，不管事务是否提交都会记录下来。例如，此时将要做的是update students set stuName='小强' where id=1; 那么这条操作就会被记录到 redo log buffer 中，啥？怎么又出来一个 redo log buffer ,很简单，MySQL 为了提高效率，所以将这些操作都先放在内存中去完成，然后会在某个时机将其持久化到磁盘中。
4. ![image-20220315211924682](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152119795.png)
5. MySQL执行器调用存储引擎是怎么将SQL加载到缓冲池和记录哪些日志文件的流程如下：
   - 准备更新一条SQL语句
   - MySQL(InnoDB)会先去缓冲池中查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（BufferPool）中
   - 在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中
   - innodb 会在 Buffer Pool 中执行更新操作
   - 更新后的数据会记录在 redo log buffer 中
6. 此时SQL语句已经更新完成，需要将更新的值提交，也就是需要提交本次的事务了。因为只要事务成功提交了，才会将最后的变更保存到数据库中，在提交事务前仍然会进行相关的操作
7. 将  redo Log Buffer 中的数据持久化到磁盘中。就是将 redo log buffer 中的数据写入到 redo log 磁盘文件中，一般情况下，redo log Buffer 数据写入磁盘的策略是立即刷入磁盘，如下：
8. ![image-20220315211938384](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152119526.png)
9. 到此为止，**从执行器开始调用存储引擎接口做了哪些事情呢**？
   - 准备更新一条 SQL 语句
   - MySQL（innodb）会先去缓冲池（BufferPool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（BufferPool）中
   - 在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中
   - innodb 会在 Buffer Pool 中执行更新操作
   - 更新后的数据会记录在 redo log buffer 中
   - MySQL 提交事务的时候，会将 redo log buffer 中的数据写入到 redo 日志文件中。刷磁盘可以通过 innodb_flush_log_at_trx_commit 参数来设置 
     - 值为 0 表示不刷入磁盘
     - 值为 1 表示立即刷入磁盘
     - 值为 2 表示先刷到 os cache
   - myslq 重启的时候会将 redo 日志恢复到缓冲池中

##### bin log：记录整个操作过程

1. redo log记录的东西是偏向于物理性质的，如：“对什么数据，做了什么修改”。 InnoDB 存储引擎特有的日志文件
2. bin log是偏向于逻辑性质的，类似于：“对 students 表中的 id 为 1 的记录做了更新操作”。是 MySQL 级别的日志
3. 两者的特点总结：

| 性  质   | REdo log                                                     | bin log                                                      |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 文件大小 | redo log 的大小是固定的（配置中也可以设置，一般默认的就足够了） | bin log 可通过配置参数max_bin log_size设置每个bin log文件的大小（但是一般不建议修改）。 |
| 实现方式 | 是InnoDB引擎层实现的                                         | 是 MySQL 层实现的，所有引擎都可以使用 bin log日志            |
| 记录方式 | 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志     | 通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 |
| 使用场景 | 适用于崩溃恢复(crash-safe)（这一点其实非常类似与 Redis 的持久化特征） | 适用于主从复制和数据恢复                                     |

##### bin log文件是如何刷入磁盘的

bin log在什么时候记录数据？

1. MySQL 在提交事务的时候，不仅仅会将 redo log buffer  中的数据写入到redo log 文件中，同时也会将本次修改的数据记录到 bin log文件中，同时会将本次修改的bin log文件名和修改的内容在bin log中的位置记录到redo log中，最后还会在redo log最后写入 commit 标记，这样就表示本次事务被成功的提交了
2. ![image-20220315212002795](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152120930.png)

MySQL有一个后台线程，它会在某个时刻将Buffer Pool中的脏数据刷到MySQL数据库中，这样内存和数据库的数据就保持一致了

![image-20220315212012776](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203152120920.png)



### MySQL查询 执行计划 Explain 

#### explain

MySQL中可以使用Explain、Describe获取MySQL执行Select语句的信息，来分析查询语句，不过通常使用Explain；Describe多用于查看表结构信息

~~~mysql
Explain Select 语句；
~~~

|      |             |       |      |               |      |         |      |      |       |
| ---- | ----------- | ----- | ---- | ------------- | ---- | ------- | ---- | ---- | ----- |
| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra |
|      |             |       |      |               |      |         |      |      |       |

1. id：select语句的编号，有几个select就有几个id，并且id的顺序是按照select出现的顺序增长的。如果在语句中没子查询或关联查询，只有唯一的 SELECT，每行都将显示 1。否则，内层的 SELECT 语句一般会顺序编号，对应于其在原始语句中的位置
2. select_type：表示对应行是简单还是复杂的查询
   - simple:简单查询
   - primary:复杂查询中最外层的select
   - subquery:包含在select中的子查询（不是在from子句中）
   - derived:包含在from子句中的子查询
   - union:在union中的第二个和随后的select
   - union result:从union临时表检索结果的select
3. table:当前行正在访问的表，当 from 子句中有子查询时，table列是 <derivenN> 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。当有 union 时，UNION RESULT 的 table 列的值为 <union1,2>，1和2表示参与 union 的 select 行id
4. type：表示关联类型或访问类型，即MySQL决定如歌查找表中的行
   - 最优到最差为：
   - system:系统表，少量数据，往往不需要进行磁盘IO
   - const:常量连接，对查询的某部分进行优化并将其转化为一个常量
   - eq_ref：primary key或unique key索引等值扫描，最多只会返回一条符合条件的记录
   - ref：非主键、非唯一索引等值扫描
   - range：范围扫描。通常出现在in、between、>、<、>=等操作，使用一个索引来检索给定范围的行
   - index：索引树扫描。和ALL一样，不同就是mysql只需要扫描索引树，比All快一些
   - all：全表扫描
5. possible_keys：这一列显示查询可能使用哪些索引来查找
6. key：这一列显示mysql实际采用哪个索引来优化对该表的访问
7. key_len：这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列
8. ref：这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），NULL，字段名（例：film.id）
9. rows：这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数
10. Extra：额外信息
    - distinct： 一旦mysql找到了与行相联合匹配的行，就不再搜索了
    - Using index：这发生在对表的请求列都是同一索引的部分的时候，返回的列数据只使用了索引中的信息，而没有再去访问表中的行记录。是性能高的表现
    - Using where：mysql服务器将在存储引擎检索行后再进行过滤。就是先读取整行数据，再按 where 条件进行检查，符合就留下，不符合就丢弃
    - Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化
    - Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。

#### explain扩展

1. Explain extended：会在 explain  的基础上额外提供一些查询优化的信息。紧随其后通过 show warnings 命令可以 得到优化后的查询语句，从而看出优化器优化了什么。额外还有 filtered 列，是一个半分比的值，rows * filtered/100 可以估算出将要和 explain 中前一个表进行连接的行数（前一个表指 explain 中的id值比当前表id值小的表）

|      |             |       |      |               |      |         |      |      |          |       |
| ---- | ----------- | ----- | ---- | ------------- | ---- | ------- | ---- | ---- | -------- | ----- |
| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
|      |             |       |      |               |      |         |      |      |          |       |

2. Explain partitions：相比 explain 多了个 partitions 字段，如果查询是基于分区表的话，会显示查询将访问的分区

---



### SQL查询语句执行先后顺序

~~~mysql
select * from student where age='zhangsan' group by age having age>10 order by age
~~~

1. from
2. where
3. group by：将过滤出来的数据进行分组
4. having：对已经分组的数据进行过滤条件
5. select：需要的字段
6. order by：对结果集进行排序

---





### 索引

索引是在存储引擎层实现的，所以不同存储引擎具有不同的所以类型和实现。

索引是帮助MySQL高效获取数据的数据结构

### 磁盘相关知识

1. 系统从磁盘读取数据到内存时，是以“磁盘块”为基本单位的，位于同一磁盘块中的数据会被一次性读取出来，而不是需要什么取什么

2. InnoDB存储引擎中，有“页”的概念，页是磁盘管理的最小单位。InnoDB存储引擎中默认每个页的大小为16kb，可通过参数innodb_page_size将页大小设置为4k、8、16k

   ~~~mysql
   #查看 页 大小命令
   mysql> show variables like 'innodb_page_size'
   ~~~

3. 然而系统一个磁盘块的存储空间往往没有这么大，因此InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。InnoDB在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率

### B树

1. 一种用于查找的平衡树，但是不是二叉树，就是平衡多路查找树
2. 能够用来存储排序后的数据

#### 性质

1. B树的阶：子节点数目的最大值
2. 每个节点中，包含数据的关键字key、数据Data、指向子节点的指针

---

### B+树

1. B树上做的优化
2. InnoDB存储引擎用B+树，实现的索引
3. 所有数据记录在叶子节点上，其数值是按照大小顺序存放在同一层的叶子节点上，非叶子节点只存放key值信息，这样大大加大每个节点存储key的数量，降低了B+tree 的高度
4. 所有叶子节点之间有一个链指针

#### MySQL索引

###### 索引分类

1. 照数据的存储方式分类
   - 聚集索引
     - 存放的物理顺序和列中的顺序一样，一般设置主键索引就为聚集索引
     - 一个表只能有一个聚集索引，因为主键的作用就是把表的数据格式转换为索引的格式存放
     - 例如select * from xx where id="12":根据索引定位到12所在的叶节点，然后通过叶节点获取id=12的数据行
   - 非聚集索引
     - 例如：User表中的name字段加上索引
     - 和聚集索引一样，同样是采用平衡多路查找树作为索引的数据结构，索引树结构中各节点的值来自表中的索引字段。例如：User表中的name字段加上索引。那么索引就是由name字段中的值构成的
     - 通过非聚集索引第一次只能查到记录对应的主键，然后再通过主键的值进行聚集索引找到需要的数据
     - 每次给字段建一个新索引，字段中的数据就会被复制一份出来，用于生成索引。每个索引互相不存在关联**
   - 两个索引的区别：聚集索引一张表只能有一个，然而非聚集索引一张表 可以有多个
2. 应用层次
   - 单列索引
     - 主键索引
     - 普通索引
     - 唯一索引
       - 和普通索引基本类似，不过唯一索引所在列的值必须唯一，可以为null值。
   - 组合索引
     - 多个字段上创建的索引
     - 使用组合索引时，遵循最左前缀集合
     - 例如：index (a,b,c) 那么 索引支持a | a、b | abc 这三种组合进行查找，但是不支持b | c | b、c 这样的查找，必须按照索引字段创建的顺序来
   - 全文索引  fulltext
     - 通过关键字的匹配来进行查询过滤=》基于相似度的查询
3. 存储结构
   - B树索引
   - B+树索引
   - Hash索引
   - 等

索引定位数据：查询到B+树叶子节点后，遍历叶子节点的数据页，从而找出该条记录



### InnoDB的索引类型

#### B+树索引

1. InnoDB的B+树索引分为：主索引（聚簇索引）和辅助索引（非聚簇索引）

2. 主索引：

   - 以主键作为B+树索引的键值所构成的B+树索引，叶子节点data域记录着完整的数据记录，这种索引方式被称为**聚簇索引**，因为无法把数据行存放在两个不同的地方（InnoDB的数据文件本身就是索引文件），所以一个表只有一个聚簇索引。图中：数字代表主键值

   - ![](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/20220311150916.png))

     

3. 辅助索引：叶子节点data域记录着主键的值，因此使用辅助索引进行查找时，需要先查到主键值，然后再到主索引中进行查找。单词代表非主键的列值

   - ![](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/20220311151051.png)

#### Hash索引

Hash索引基于Hash表实现，对于每一行数据，存储引擎会对索引列通过hash算法进行hash计算得到hash码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码值作为哈希表的key，将指向数据行的指针作为哈希表的value值。这样查找一个数据的时间复杂度就是O(1)，一般用于精确查找

#### 区别

1. 因为两者数据结构上的差异导致它们的使用场景也不同，哈希索引一般多用于精确的等值查找，B+索引则多用于除了精确的等值查找外的其他查找。在大多数情况下，会选择使用B+树索引



[索引覆盖与下推](https://www.jianshu.com/p/d0d3de6832b9)

### 索引覆盖

1. 只需要在一颗索引树就能获取SQL所需的所有列数据，无需回表，速度更快
2. explain的输出结果Extra字段为Using index时，能够触发索引覆盖

#### 索引下推 ICP 优化

Index Condition pushdown

在使用非主键索引进行索引查询时，首先根据索引来查找记录，然后在根据where条件来过滤记录

![image-20220316131642324](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220316131642324.png)

![image-20220316131658595](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220316131658595.png)

图 1 中，在 (name,age) 索引里面特意去掉了 age 的值，**这个过程 InnoDB 并不会去看 age 的值**，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。

图 2 跟图 1 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次



### MySQL强制索引

强制索引，即指定本次查询使用某个特定的索引，这样就可以避免MySQL优化器使用低效的索引

~~~mysql 
select * 
from table 
force index (index_list)
where condition;
~~~





---

### MySQL日志

任何一种数据库中，都会有各种各样的日志，记录着数据库工作的各种操作。

MySQL中主要包括的日志：二进制日志、错误日志、查询日志、慢查询日志、事务日志(包括redo log、undo log )等等。其中比较重要的是二进制日志(binlog)、重做日志(redo log)、回滚日志(undo log)

#### Binarylog

https://zhuanlan.zhihu.com/p/227864607

Mysql会把所有表结构变更，以及表数据修改的操作 记录到一个二进制日志文件，也即BinaryLog文件，简称binlog。使用任何存储引擎的Mysql数据库都会记录binlog日志

逻辑日志：可以简单理解为记录的是sql语句

物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更

binlog是通过追加的方式进行写入的，通过设置max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志

binlog日志是以事件的形式记录对MySQL的操作，还记录着各个操作消耗的时间

恢复事件4 - 事件1234之间的数据操作：

```mysql
$ mysqlbinlog --start-position=4 --stop-position=1234 /usr/local/var/mysql/binlog.000001 | mysql -uroot -p
```



##### binlog工作原理

binlog是MySQL用来记录数据库表结构变更以及表数据修改的二进制日志，它只会记录表的变更操作，但不会记录select和show这种查询操作

###### binlog常用的场景

1. 数据恢复
   - 误删数据之后可以通过mysql binlog工具恢复数据
2. 主从复制
   - 主库开启binlog，然后将binlog传给从库(各个slave端)，从库接收到之后读取内容写入从库，实现主从数据一致
3. 审计
   - 通过二进制日志中的信息进行审计，判断是否对数据库进行注入攻击

binlog文件包含两种类型：

1. 索引文件(文件名后缀为.index)：用于记录哪些日志文件正在被使用
2. 日志文件(文件名为.00000*)：记录数据库所有的DDL和DML语句事件

###### binlog刷盘时机

对于InnoDB存储引擎而言，只有在事务提交时才会记录biglog，此时记录还在内存中，那么biglog是什么时候刷到磁盘中的呢？mysql通过sync_binlog参数控制binlog的刷盘时机，取值范围是0-N：

- 0：不去强制要求，由系统自行判断何时写入磁盘；
- 1：每次commit的时候都要将binlog写入磁盘；
- N：每N个事务，才会将binlog写入磁盘

从上面可以看出，sync_binlog最安全的是设置是1，这也是MySQL 5.7.7之后版本的默认值



binlog如何记录数据库操作的？

###### binlog的3种记录模式

1. ROW：记录的是每一行被修改的数据     5.7之后默认
   - ![image-20220324095057636](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220324095057636.png)
2. STATEMENT：记录每一条修改数据的SQL语句（批量修改时，记录的不是单条SQL语句，而是批量修改的SQL语句事件）  5.7之前默认
3. MIXED：statement和row模式的混合

通过binlog_format=" xxx" 来修改日志模式

| 记录模式  | 优点                                     | 缺点                                                         |
| --------- | ---------------------------------------- | ------------------------------------------------------------ |
| ROW       | 能清楚记录每一个行数据的修改细节         | 批量操作，会产生大量的日志，尤其是alter table会让日志文件大小暴涨 |
| STATEMENT | 日志量小，减少磁盘IO，提升存储和恢复速度 | 在某些情况下会导致主从数据不一致，比如Sql语句中有last_insert_id()、now()等函数。 |
| MIXED     | 准确性强，文件大小适中                   | 当binlog format 设置为mixed时，普通复制不会有问题，但是级联复制在特殊情况下会binlog丢失。 |



###### Binlog文件结构

binlog文件记录的是对数据库的各种修改操作，用来记录修改操作的数据结构的Log event。不同的修改操作对应着不同的log event

常用的log event：Query event、Row event、Xid event等等

binlog文件的内容就是各种log event的集合

![image-20220323230705990](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203232307725.png)



###### Binlog写入机制

1. 根据设置的记录模式和操作生成相应的log event
2. 事务执行过程中产生log event会先写入缓冲区，每个事务线程都有一个缓冲区，Log Event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用于存放不支持事务的信息；另一个是trx_cache用于存放支持事务的信息
3. 事务在提交阶段会将产生的log event写入到外部binlog文件中。不同事务以串行方式将log event写入binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event



###### 配置binlog参数  

windows中 my.cnf文件，在mysqld节中修改配置信息

~~~mysql
[mysqld]
#设置记录模式
binlog_format = mixed

# 设置日志路径，注意路经需要mysql用户有权限写
log-bin = /data/mysql/logs/mysql-bin.log

# 设置binlog清理时间
expire_logs_days = 7

# binlog每个日志文件大小
max_binlog_size = 100m

# binlog缓存大小
binlog_cache_size = 4m

# 最大binlog缓存大小
max_binlog_cache_size = 512m
~~~



#### 错误日志

记录mysqld启动和停止时、服务器运行过程中发生任何严重错误的相关信息。

错误日志是默认开启的，默认存放目录var/lib/mysql  默认文件名为 主机.err

![image-20220323233829559](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203232338770.png)



#### 查询日志

查询日志中记录了客户端所有操作语句，但是二进制日志不包含查询数据的日志

默认情况下，查询日志是未开启的。可以设置开启：

~~~mysql
#该选项用来开启查询日志 ， 可选值 ： 0 或者 1 ； 0 代表关闭， 1 代表开启 
general_log=1

#设置日志的文件名 ， 如果没有指定， 默认的文件名为 host_name.log 
general_log_file=file_name
~~~



#### 慢查询日志

慢查询日志记录了所有执行事件超过参数long_query_time设置值并且扫描记录数不小于min_examined_row_limit的所有的sql语句的日志

long_query_time默认为10s，最小为0，精度可以到微妙

慢查询日志默认是关闭的。通过设置来控制慢查询日志：

~~~sql
# 该参数用来控制慢查询日志是否开启， 可取值： 1 和 0 ， 1 代表开启， 0 代表关闭
slow_query_log=1 

# 该参数用来指定慢查询日志的文件名
slow_query_log_file=slow_query.log

# 该选项用来配置查询的时间限制， 超过这个时间将认为值慢查询， 将需要进行日志记录， 默认10s
long_query_time=10
~~~

![image-20220323234539004](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/202203232345184.png)

https://blog.csdn.net/m_awdawdw/article/details/107665827



#### 重做日志(redo log)

redo log是MySQL中innodb引擎级别，用来记录innodb存储引擎的事务操作的日志，不管事务是否提交都会记录下来，用于数据回复。

当数据库发生故障，innoDB存储引擎会使用redo log恢复到发生故障前的时刻，以此来保证数据的完整性。

确保事务的持久性，防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性

将参数innodb_flush_log_at_tx_commit设置为1，那么在执行commit时会将redo log同步写到磁盘



#### binlog和redo log区别

1. binlog属于MySQL server层面，redo log属于Innodb层面，这样数据库用别的存储引擎时就可以达到一致性的要求
2. binlog是逻辑日志，记录的是sql语句的原始逻辑；redo log是物理日志，记录该数据页更新的内容
3. binglog是追加写，一份文件写到一定大小的时候就会换下一个文件写入，不会覆盖；redo log是循环下，日志空间大小固定
4. binlog可以作为恢复数据使用，主从复制搭建；redo log作业异常宕机、介质故障后的恢复数据使用



#### 回滚日志(undo log)

除了记录redo log之外，当进行数据修改时，还会记录 undo log，undo log用于数据的撤回操作，他保留了记录修改前的内容。

保存了事务发生之前的数据的一个版本，通过undo log可以实现事务回滚，并且可以根据undo log回溯到某个特定的版本的数据，实现MVCC(多版本并发控制)





### MySQL主从同步

主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器(master)，其余的服务器充当从服务器(slave)

因为复制是异步进行的，所以从服务器不需要一直连着主服务器，从服务器甚至可以通过拨号断断续续的连接主服务器。通过配置文件，可以指定复制所有的数据库、某个数据库甚至是数据库上的某个表

##### 为什么要做主从同步

1. 读写分离，使数据库支撑更大的并发
2. 在主服务器上生成实时数据，从服务器上分析这些数据，从而提高主服务器的性能
3. 数据备份，保证数据的安全

---



### MySQL锁机制

#### 按照锁粒度分类

锁粒度从大到小：表锁、页锁、行锁；以及特殊场景下使用的全局锁

##### 表锁

表级别的锁是MySQL各种存储引擎中最大颗粒度的锁机制。该锁机制最大的特定是实现逻辑简单、带来的系统负面影响最小。索引获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所有可以很好的避免死锁问题

缺点：锁定资源争用的概率最高，大大降低了并发度

使用表级锁的主要是MyISAM、Memory、Csv等一些非事务型存储引擎，当然Innodb也是支持，不过默认并不是表锁定

##### 页锁

页锁的锁定颗粒的介于表锁和行锁之间，能提供的并发处理能力页锁介于二者之间。会发生死锁问题

使用页锁的主要是BerkeleyDB存储引擎

##### 行锁

行级锁分为：共享锁和排他锁

锁定对象的颗粒的最小，所有发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力

缺点：由于资源锁定颗粒的最小，所有每次获取锁和释放锁需要做的事情更多，带来的消耗也就更大，此外行级锁最容易发生死锁

InnoDB存储引擎主要使用行锁

适用场景：表级锁更适合查询为主，只有少量按索引条件更新数据的应用；行级锁更适合有大量按索引条件并发风险数据的情况，同时又有并发查询的应用场景

##### 全局锁

全局锁，是对整个数据库实例加锁。使用场景：一般为全库逻辑备份

#### 按照锁级别分类

共享锁、排他锁、意向锁

##### 共享(读)锁

共享锁，也叫读锁，是读取操作(select)时创建的锁。其他用户可以并发读取数据，但是在读锁未释放前，也就是查询事务结束前，任何事务都不能对数据进行修改(获取数据上的写锁)，直到已释放所有读锁

~~~sql
#sql显示加锁写法：

select xxxxx      Lock in share mode;

# lock in share mode:查询语句后面添加了该语句，mysql会对查询结果中的每一行都加读锁
~~~



##### 排他(写)锁

排他锁，又叫写锁、独占锁，当A事务对数据data加上写锁后，其他事务不能再对数据data加任何类型的锁，获取写锁的事务既能读取数据，又能修改数据

~~~sql
select...  for update;
~~~

##### 意向锁 (Intention Lock)

意向锁属于表级锁，其设计目的主要目的是为了表明某个事务正在锁定一行或将要锁定一行

1. 意向共享锁(IS)：表示事务准备给数据行加共享锁，也就是说一个数据行加共享锁前必须先取得该表的意向共享锁
2. 意向排他锁(IX)：表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的意向排他锁

意向锁是InnoDB自动加的，无需用户干预

对应Insert、update、delete，Innodb会自动给设计的数据加排他锁；对于一般的select语句，Innodb不会加任何锁，事务可以通过以下语句显示加共享锁或排他锁

~~~sql
共享锁：SELECT … LOCK IN SHARE MODE;
排他锁：SELECT … FOR UPDATE;
~~~



https://blog.csdn.net/cy973071263/article/details/105188519?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&utm_relevant_index=10

#### InnoDb引擎为解决幻读等并发场景下事务存在的数据问题，引入的锁

##### 行记录锁(Record Locks)

单个行记录上的锁，也就是日常认为的行锁

##### 间隙锁(Gap Locks)

锁定一个范围，但不包括记录本身（只不过它的锁粒度比记录锁的锁整行更大一些，他是锁住了某个范围内的多个行，包括根本不存在的数据）。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。该锁只会在隔离级别是RR或者以上的级别内存在。间隙锁的目的是为了让其他事务无法在间隙中新增数据

##### 临键锁(next-key Lock)  行锁+间隙锁组合

它是记录锁和间隙锁的结合，该记录和它前面的区间都被锁定。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。next-key锁是InnoDB默认的锁



假设有记录1, 3, 5, 7，现在记录5上加next-key lock，则会锁定区间(3, 5]，任何试图插入到这个区间的记录都会阻塞。

 

注意，由于其效果相当于(3, 5)上的gap lock加5上的record lock，而且gap lock是可重入的，相互不阻塞的(上文讲过)，当其它事务试图获取(3, 5)的gap lock时，不会被阻塞；但如果要获取5上的record lock，就会阻塞；如果要获取5上的next-key lock，同样会阻塞

这三种锁都是排他锁

这三种锁都是加在索引上的。假设有1，3，5，7，则5上的记录锁会锁住5，gap lock会锁住（3，5），next-key lock会锁住（3，5]



#### 面向编程的两种锁思想

乐观锁和悲观锁并不是Mysql或数据库独有的概念，是两种并发控制的思想

主要区别在于：操作共享数据时，“悲观锁”即认为数据出现冲突的可能性更大，而“乐观锁”则是认为大部分情况不会出现冲突，进而决定是否采取排他性措施。

反映到 MySQL 数据库应用开发中，悲观锁一般就是利用类似 SELECT … FOR UPDATE 这样的语句，对数据加锁，避免其他事务意外修改数据。乐观锁则与 Java 并发包中的 AtomicFieldUpdater 类似，也是利用 CAS 机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。

MySQL的多版本并发控制 （MVCC），其本质就可以看作是种乐观锁机制，而排他性的读写锁、两阶段锁等则是悲观锁的实现


##### 悲观锁

假定并发冲突，在查询完数据的时候就把事务锁起来，直到提交事务。

实现方式：使用数据库中锁机制

##### 乐观锁

假设不会发生并发冲突，只在提交操作的时候检查数据是否被修改过。

给表增加version字段，在修改提交之前检查version与原来的version值是否相等。若相等，表示数据没有被修改，可以更新；否则数据为脏数据不能更新。

实现方式：乐观锁一般使用版本号机制或CAS算法实现



#### 自增锁 (auto-inc锁)

自增锁是一种特殊的**表级锁**，主要用于事务中插入自增字段，也就是我们最常用的自增主键id。通过innodb_autoinc_lock_mode参数可以设置自增主键的生成策略。防止并发插入数据的时候自增id出现异常。

当一张表的某个字段是自增列时，innodb会在该索引的末位加一个排它锁。为了访问这个自增的数值，需要加一个表级锁，不过这个表级锁的持续时间只有当前sql，而不是整个事务，即当前sql执行完，该表级锁就释放了。其他session无法在这个表级锁持有时插入任何记录

----

### truncate、delete、drop

truncate和delete只删数据，不删除表的结构；drop将删除表的数据、结构、被依赖的约束、触发器、索引

一般来说，执行速度：drop>truncate>delete



### MySQL常见控制流函数

case when  ....   then ....else ....  end ：适用于增删改查各类语句

~~~sql
update user_info u
set  u.balance= 

case 
when u.set='女' and u.age>18 
then u.balance+10
else u.balance+5
end

where u.create_time>='2020-01-01';

~~~























![image-20220325145714186](https://gitee.com/qianchao_repo/pic-typora/raw/master/img/image-20220325145714186.png)

~~~

老公，咱们也能这样白头偕老该多好啊！

老伴儿啊，我仿佛又听到了从前你问过我的话。

一个看到了未来，一个看到了过去
一生很短。
~~~

