## 分库分表

![image-20220509213552417](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/sharding_img/202205092136558.png)



### 如何拆分

![image-20220509221714389](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/sharding_img/202205092217508.png)

### 为什么分库分表



### 分库分表中间件

常用sharding-jdbc、MyCat

1. sharding-jdbc
   - 这种client层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合sharding-jdbc的依赖
2. MyCat
   - 这种proxy层方案的缺点在于需要部署，自己及运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行

### 如何对数据库进行垂直拆分或者水平拆分的

1. 水平拆分的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。
2. 垂直拆分的意思，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。
   - 这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。

 

还有表层面的拆分，就是分表，将一个表变成N个表，就是让每个表的数据量控制在一定范围内，保证SQL的性能。否则单表数据量越大，SQL性能就越差。一般是200万行左右，不要太多，但是也得看具体你怎么操作，也可能是500万，或者是100万。你的SQL越复杂，就最好让单表行数越少。

 

无论是分库了还是分表了，那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，中间件可以根据你指定的某个字段值，比如说userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。

 

考虑一下，你的项目里该如何分库分表？一般来说，

垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；

水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都ok了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。

 

分库分表的方式

1. 一种是按照range来分，就是每个库一段连续的数据，这个一般是按比如时间范围来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了
   - range来分，好处在于说，后面扩容的时候，就很容易，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用range，要看场景，你的用户不是仅仅访问最新的数据，而是均匀的访问现在的数据以及历史的数据
2. hash分法：某个字段hash一下均匀分散，这个较为常用。好处在于说，可以平均分配没给库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的这么一个过程





### 如何让系统从未分库分表动态切换到分库分表上？

分库、分表、中间件那些都准备好之后

生产环境如何动态的切换到分库分表

方案一：停机迁移方案，比较low



![image-20220509231915146](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/sharding_img/202205092319268.png)

 

方案二：不停机双写方案

这个是我们常用的一种迁移方案，比较靠谱一些，不用停机

简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，都除了对老库增删改，都加上对新库的增删改，这就是所谓双写，同时写俩库，老库和新库。

然后系统部署之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据gmt_modified这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。

接着导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。

接着当数据完全一致了，就ok了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干了

![image-20220509235656289](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/sharding_img/202205092356401.png)

---



### 如何设计动态扩容的分库分表方案



---

### 分库分表后，id主键如何处理

分库分表后，id主键问题是必然要面对的问题，这个id怎么生成？若根据每个表的自增主键，那肯定不对，每个表的id可能会相同，所以需要一个全局的id来支撑

如下为id重复的情况：

![image-20220510220437156](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/sharding_img/202205102204992.png)

1. 数据库自增id
   - 就是说你的系统里每次得到一个id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个id。拿到这个id之后再往对应的分库分表里去写入
   - 好处：方便简单
   - 缺点：单库生成自增id，在高并发场景下会有瓶颈
2. uuid
   - 好处：本地生成不用基于数据库
   - 缺点：uuid是一个无序的字符串，太长了，不适合作为主键
3. 系统当前时间
   - 存在问题：高并发场景下，比如一秒几千并发，会有重复的情况，所以基本不考虑使用
   - 适合场景：使用该时间与业务字段拼接作为id场景
4. snowflake算法(雪花算法)

twitter开源的分布式id生成算法，就是一个64位的long型id

例如：

0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001  |  11001  | 0000 00000000

其中：

1bit：第一位为0，代表正数

41 bit：表示的是毫秒级时间戳，41 bit可以表示的数字多达2^41 - 1，也就是可以表示2 ^ 41 - 1个毫秒值，换算成年就是2^41 /1000606024365  = 69年的时间

10 bit：记录工作机器id，代表的是这个服务最多可以部署在2^10台机器上，也就是1024台机器。但是10 bit里5个bit代表机房id（dataceterId)，5个bit代表机器id(workerId)。意思就是最多代表2 ^ 5个机房（32个机房），每个机房里可以代表2 ^ 5个机器（32台机器）

12 bit：存储序列号，同一毫秒时间戳时，通过这个递增的序列化来区分。这个是用来记录同一个毫秒内产生的不同id，12 bit可以代表的最大正整数是2 ^ 12 - 1 = 4096，也就是说可以用这个12bit代表的数字来区分同一个毫秒内的4096个不同的id



可以将雪花算法作为一个单独的服务进行部署，需要全局唯一id的系统，请求雪花服务获取Id即可。

snowflake算法服务，会判断一下，当前这个请求是否是，机房17的机器25，在2175/11/7 12:12:14时间点发送过来的第一个请求，如果是第一个请求则生成一个id

 

假设，在2175/11/7 12:12:14.000时间里，机房17的机器25，发送了第二条消息，snowflake算法服务，会发现说机房17的机器25，在2175/11/7 12:12:14.000时间里，在这一毫秒，之前已经生成过一个id了，此时如果你同一个机房，同一个机器，在同一个毫秒内，再次要求生成一个id，此时id要加1

![image-20220510220715186](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/sharding_img/202205102207321.png)

https://bbs.huaweicloud.com/blogs/344958

https://zhuanlan.zhihu.com/p/402822041

~~~java
@Data
public class IdWorker{

    private long workerId;//机房的机器
    private long datacenterId;//机房
    private long sequence;

    //构造函数seq参数可要可不要
    public IdWorker(long workerId, long datacenterId, long sequence){
		// 检查传递进来的机房id和机器id不能超过32，不能小于0
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0",maxWorkerId));
        }
        if (datacenterId > maxDatacenterId || datacenterId < 0) {
            throw new IllegalArgumentException(String.format("datacenter Id can't be greater than %d or less than 0",maxDatacenterId));
        }
        this.workerId = workerId;
        this.datacenterId = datacenterId;
        this.sequence = sequence;
    }
	//初始时间戳(纪元） 一般为当前时间2022-05-10 22:59:27
    private long initEpoch = 1652194767190L;
    // 记录最后使用的毫秒时间戳，主要用于判断是否同一毫秒，以及用于服务器时钟回拨判断
    private long lastTimestamp = -1L;
	//datacenterId占用的位数
    private long datacenterIdBits = 5L;
    //workerId占用的位数
    private long workerIdBits = 5L;
    
   // dataCenterId占用5个比特位，最大值31
   // 0000000000000000000000000000000000000000000000000000000000011111
    // 这个是二进制运算，就是5 bit最多只能有31个数字，也就是说机器id最多只能是32以内
    private long maxWorkerId = -1L ^ (-1L << workerIdBits); 
   
     // workId占用5个比特位，最大值31
     // 0000000000000000000000000000000000000000000000000000000000011111
     // 这个是一个意思，就是5 bit最多只能有31个数字，机房id最多只能是32以内
    private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);
    
    //序列号，最后12位
    private long sequenceBits = 12L;
     // 同一毫秒内的最新序号，最大值可为 2^12 - 1 = 4095
    private long sequenceMask = -1L ^ (-1L << sequenceBits);
    
	//workerId需要左移的位数
    private long workerIdShift = sequenceBits;
    //datacenterId需要左移的位数
    private long datacenterIdShift = sequenceBits + workerIdBits;
    //时间戳需要左移的位数：12+5+5
    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;
   

  
    public long getTimestamp(){
        return System.currentTimeMillis();
    }

   /**
    *通过雪花算法生成下一个id,需要进行同步
    */
public synchronized long nextId() {
		// 获取当前时间戳，单位是毫秒
        long timestamp = System.currentTimeMillis();;

       // 当前时间小于上一次生成id使用的时间，可能出现服务器时钟回拨问题
        if (timestamp < lastTimestamp) {
            System.err.printf("可能出现服务器时钟回拨问题，请检查服务器时间。当前服务器时间戳：%d，上一次使用时间戳：%d", lastTimestamp);
            throw new RuntimeException(String.format("Clock moved backwards.  Refusing to generate id for %d milliseconds",
                    lastTimestamp - timestamp));
        }

       // 0
	  // 在同一个毫秒内，又发送了一个请求生成一个id，0 -> 1
       // 还是在同一毫秒内，则将序列号递增1，序列号最大值为4095
        if (lastTimestamp == timestamp) {
            // 这个意思是说一个毫秒内最多只能有4096个数字，无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，
            //避免你自己传递个sequence超过了4096这个范围
            
             // 序列号的最大值是4095，使用掩码（最低12位为1，高位都为0）进行位与运行后如果值为0，则自增后的序列号超过了4095
      // 那么就使用新的时间戳
            sequence = (sequence + 1) & sequenceMask; 
            if (sequence == 0) {
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            // 不在同一毫秒内，则序列号重新从0开始，序列号最大值为4095
            sequence = 0;
        }

	   // 记录一下最近一次生成id的时间戳，单位是毫秒
        lastTimestamp = timestamp;

      // 核心算法，将不同部分的数值移动到指定的位置，然后进行或运行
    
       // 这儿就是将时间戳左移，放到41 bit那儿；将机房id左移放到5 bit那儿；将机器id左移放到5 bit那儿；将序号放最后10 bit；最后拼接起来成一个64 bit的二进制数字，转换成10进制就是个long型
        return ((timestamp - initEpoch) << timestampLeftShift) |
                (datacenterId << datacenterIdShift) |
                (workerId << workerIdShift) |
                sequence;
    }

//  0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000


    /**
   * 获取指定时间戳的接下来的时间戳，也可以说是下一毫秒
   *
   * @param lastTimeMillis 指定毫秒时间戳
   * @return 时间戳
   */
    private long tilNextMillis(long lastTimestamp) {
        long timestamp =System.currentTimeMillis();
        while (timestamp <= lastTimestamp) {
            timestamp =System.currentTimeMillis();
        }
        return timestamp;
    }

    //---------------测试---------------
    public static void main(String[] args) {
        IdWorker worker = new IdWorker(1,1,1);
        for (int i = 0; i < 30; i++) {
            System.out.println(worker.nextId());
        }
        
    // 生成50个id
    Set<Long> set = new TreeSet<>();
    for (int i = 0; i < 50; i++) {
      set.add(worker.nextId());
    }
    System.out.println(set.size());
    System.out.println(set);
    }
    
    // 验证生成100万个id需要多久
    long startTime = System.currentTimeMillis();
    for (int i = 0; i < 1000000; i++) {
      worker.nextId();
    }
    System.out.println(System.currentTimeMillis() - startTime);

}

~~~





大概这个意思就是说41 bit，就是当前毫秒单位的一个时间戳，就这意思；然后5 bit是你传递进来的一个机房id（但是最大只能是32以内），5 bit是你传递进来的机器id（但是最大只能是32以内），剩下的那个10 bit序列号，就是如果跟你上次生成id的时间还在一个毫秒内，那么会把顺序给你累加，最多在4096个序号以内。

 

所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是0。然后每次接收到一个请求，说这个机房的这个机器要生成一个id，你就找到对应的Worker，生成。

 

他这个算法生成的时候，会把当前毫秒放到41 bit中，然后5 bit是机房id，5 bit是机器id，接着就是判断上一次生成id的时间如果跟这次不一样，序号就自动从0开始；要是上次的时间跟现在还是在一个毫秒内，他就把seq累加1，就是自动生成一个毫秒的不同的序号。

 

这个算法那，可以确保说每个机房每个机器每一毫秒，最多生成4096个不重复的id。

 

利用这个snowflake算法，你可以开发自己公司的服务，甚至对于机房id和机器id，反正给你预留了5 bit + 5 bit，你换成别的有业务含义的东西也可以的。

 

这个snowflake算法相对来说还是比较靠谱的，所以你要真是搞分布式id生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了









