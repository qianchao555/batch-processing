

### MySQL体系结构与存储引擎

MySQL由连接池、SQL接口、解析器、优化器、缓存、存储引擎等组成。可以分为三层：MySQL Server层、存储引擎层、文件系统层。MySQL Server层又包括连接层和SQL层

Connectors不属于以上任何一层，可以将Connectors理解为各种客户端、应用服务，主要是指不同语言与MySQL的交互

MySQL基础架构图如下：

![MySQL体系结构图](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/5-200622094009461.png)



#### MySQL Server

##### 连接层

1. 应用程序通过接口(JDBC、ODBC等等)来连接MySQL，最先处理的是连接层。连接层包括通信协议、线程处理、用户密码认证3部分
   - 通信协议负责检测客户端版本是否兼容 MySQL 服务端
   - 线程处理是指每一个连接请求都会分配一个对应的线程，相当于一条 SQL 对应一个线程，一个线程对应一个逻辑 CPU，在多个逻辑 CPU 之间进行切换
   - 密码认证用来验证用户创建的账号、密码，以及 host 主机授权是否可以连接到 MySQL 服务器
2. 连接池（Connection Pool）属于连接层。由于每次建立连接都需要消耗很多时间，连接池的作用就是将用户连接、用户名、密码、权限校验、线程处理等需要缓存的需求缓存下来，下次可以直接用已经建立好的连接，提升服务器性能

##### SQL层

SQL层是MySQL的核心，核心服务都在这一层实现。主要包括权限判断、查询缓存、解析器、预处理、查询优化器、缓存、执行计划

1. 权限判断可以审核用户有没有访问某个库、某个表，或者表里某行数据的权限
2. 查询缓存通过 Query Cache 进行操作，如果数据在 Query Cache 中，则直接返回结果给客户端，不必再进行查询解析、优化和执行等过程
3. 查询解析器针对 SQL 语句进行解析，判断语法是否正确
4. 预处理器对解析器无法解析的语义进行处理
5. 查询优化器对 SQL 进行改写和相应的优化，并生成最优的执行计划，就可以调用程序的 API 接口，通过存储引擎层访问数据
5. ![image-20220326212518213](C:/Users/Administrator/AppData/Roaming/Typora/typora-user-images/image-20220326212518213.png)

Management Services & Utilities、SQL Interface、Parser、Optimizer 和 Caches & Buffers 属于 SQL 层，详细说明如下表所示。

| 名称                            | 说明                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| Management Services & Utilities | MySQL 的系统管理和控制工具，包括备份恢复、MySQL 复制、集群等。 |
| SQL Interface（SQL 接口）       | 用来接收用户的 SQL 命令，返回用户需要查询的结果。例如 SELECT FROM 就是调用 SQL Interface。 |
| Parser（查询解析器）            | 在 SQL 命令传递到解析器的时候会被解析器验证和解析，以便 MySQL 优化器可以识别的数据结构或返回 SQL 语句的错误。 |
| Optimizer（查询优化器）         | SQL 语句在查询之前会使用查询优化器对查询进行优化，同时验证用户是否有权限进行查询，缓存中是否有可用的最新数据。它使用“选取-投影-连接”策略进行查询。例如 `SELECT id, name FROM student WHERE gender = "女";`语句中，SELECT 查询先根据 WHERE 语句进行选取，而不是将表全部查询出来以后再进行 gender 过滤。SELECT 查询先根据 id 和 name 进行属性投影，而不是将属性全部取出以后再进行过滤，将这两个查询条件连接起来生成最终查询结果。 |
| Caches & Buffers（查询缓存）    | 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的，比如表缓存、记录缓存、key 缓存、权限缓存等。 |



#### 存储引擎层

1. 存储引擎层是 MySQL 数据库区别于其他数据库最核心的一点，也是 MySQL 最具特色的一个地方。主要负责 MySQL 中数据的存储和提取
2. 因为在关系数据库中，数据的存储是以表的形式存储的，所以存储引擎也可以称为表类型（即存储和操作此表的类型）

#### 文件系统层

文件系统层主要是将数据库的数据存储在操作系统的文件系统之上，并完成与存储引擎的交互



---

### InnoDB体系结构

#### 数据库和数据库实例

MySQL是一个单进程多线程模型的数据库。

数据库实例：就是进程加内存的组合，在操作数据时，是在数据库实例里面进行的，也就是内存。而在内存中的数据，会根据刷新机制刷到磁盘上，那么谁来刷新？— —线程。

一条数据从内存刷新到磁盘的过程如下，也即形成了InnoDB的体系结构

![image-20220605171450193](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206051714318.png)

InnoDB体系结构实际上由内存结构、线程、磁盘文件这三次组成

#### InnoDB存储结构

InnoDB逻辑存储单元分为：表空间、段、区、页

层级关系为：tablespace->segment->extent（64个page，1MB) ->page

![image-20220605171810479](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206051718600.png)

1. 表空间

   - InnoDB 是以页为单位管理存储空间的，我们的聚簇索引（也就是完整的表数据）和其他的二级索引都是以 B+树的形式保存到表空间的，而B+树的节点就是数据页以页的角度看，每个页都有File Header这个部分，其中包含一个属性fil_page_arch_log_no_or_space_id保存页属于哪个表空间。同时每一个页对应着一个页号，这个页号4个字节组成，所以一个表空间最多可以拥有$$2^{32}$$次方个页。按照页默认大小16k来算，那么一个表空间最多可以支持64TB的数据

   - InnoDB存储引擎中，所以数据都是存储在表空间中。表空间分为系统表空间，它以ibdata1来命名，安装数据库初始化数据的时候系统会创建一个ibdata1的表空间文件，它会存储所有数据的信息以及回滚段(undo)的信息

   - 数据库默认的ibdata1的大小是10MB，遇到高并发事务时，会受到不小的影响，建议把ibdata1的初始数值调整为1GB

   - 除了系统表空间还有就是独立表空间，**MySQL版本中，默认使用的都是独立表空间文件**，即每个表都有自己的表空间文件，而不用存储在ibdata1中。独立表空间文件存储的是：对应表的B+树数据、索引、插入缓冲等等信息，其余信息还是存储在默认表空间中

   - 每一个表都将会生成独立的文件方式来进行存储，每一个表都有一个.frm表描述文件，和一个.ibd文件

   - ![image-20220605172900714](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206051729829.png)

   - 独立表空间好处：每个表的数据和索引都会存在自己的表空间中，每个表有自己的表空间，可以实现表空间的转移，可以实现单表在不同数据库中移动，回收表空间也方便

   - 独立表空间缺点：每个表都有.frm和.ibd 两个文件描述符，如果单表增长过快，很容易出现性能问题

   - 开启，在my.cnf中设置：innodb_file_per_table

     默认为独立的表空间

     ~~~sql
     show variables like 'innodb_file_per_table';
     ON
     ~~~

   - ![image-20220605173213358](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206051732471.png)

   - 共享表空间

     - 某一个数据库所有的表和索引存放在同一个文件中，默认这个共享表空间的文件路径在data目录下。默认文件名为 ibdata1 初始化为10M，每个文件大小为10M，当每个文件都满了的时候，ibdata4会自动扩展
     - 优点：可以将表空间分成多个文件存放到各个磁盘上（表空间文件大小不受表大小的限制，如一个表可以分布在不同的文件上），数据和文件放在一起方便管理。
     - 缺点：无法在线回收空间，想要回收需要将InnoDB表中的数据备份、删除原表、然后再把数据导回到与原表结构一样的新表中。所有的数据和索引存放到一个文件中，虽然可以把一个大文件分成多个小文件，但是多个表及索引在表空间中混合存储，这样对于一个表做了大量删除操作后表空间中将会有大量的空隙，特别是对于统计分析，日值系统这类应用最不适合用共享表空间
     - 综上考虑得到：独立表空间的效率、性能比共享表空间更改，MySQL默认采用独立表空间的存储方式

   - 临时表空间：MySQL5.7加入

     - MySQL5.7把临时表的数据，从系统表空间抽离出来，形成自己的独立表空间，并把临时表的相关检索信息保存在系统信息表innodb_temp_table_info中，名称为ibtmp1，默认12MB

   - 通用表空间：MySQL5.7加入

     - 多个表空间放在同一个表空间中，可以根据活跃度来划分表，存放在不同的磁盘上，可以减少metadata的存储开销
     - 目前生产中使用很少

2. 段

   - 表空间由段组成，可以把一个表理解为一个段。通常有数据段、回滚段、索引段等等
   - 每个段由N个区和32个零散的页组成，段空间扩展是以区为单位进行扩展的
   - 通常：创建一个索引的同时就会创建两个段，分别为非叶子节点和叶子节点段
   - 一个表几个段？4个，是索引个数的两倍

3. 区

   - 由连续的页组成，是物理上连续的一段空间，一般情况下，每个区的大小由连续的64个页组成，每个页大小为16K，即大小为：1MB

4. 页

   - InnoDB的最新物理存储分配单位是页page，有数据页、回滚页等等
   - 一般情况下，一个区由64个连续的页组成，页默认大小为16KB
   - 一般情况下，一个页默认预留1/16的空间用于更新数据，真正使用的是15/16
   - 一个页最少可以存两行数据：虚拟最新行、虚拟最大行，用来限定行记录的范围，依次来保证B+tree节点是双向链表结构
   - ![image-20220605175421896](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206051754005.png)

5. 行

   - 页里面记录着行记录的信息，InnoDB存储引擎是面向列的，也就是数据是按照行存储的
   - InnoDB中有两者文件格式
     - Antelope：该文件格式下，有compact和redundant两种行记录格式
     - Barracuda：有compressed和dynamic两种行记录格式
     - show table status like '%table_name%'：row_format列对应该表使用的行格式的存储类型
     - ![image-20220605175949842](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206051759943.png)



#### 内存刷新机制

内存中的数据都会刷新到磁盘

Oracle和MySQL这种关系型数据库中，讲究日志先行策略，就是一条DML语句进入数据库之后，都会先写日志，再写数据文件

![image-20220605202550668](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206052025810.png)

1. redo log
   - redo log又称重做日志文件，用于记录事务操作的变化，记录的是**数据修改之后的记录**，增删改都是针对缓存页做操作，不管事务是否提交都会记录下来
   - 默认情况下至少有2个redo log文件，在磁盘上用ib_logfile(0~n)命名
   - redo log侧重于重做！redo log中记录的是**物理层面的数据页、偏移量**。应对的问题是：MySQL异常宕机后，如何将没来得及提交的事物数据重做出来
   - 刷盘时机：推荐事务提交后刷盘
2. data buffer
3. binlog 
   - DML语句既会写redo log文件，也会写binlog文件
   - binlog记录commit完毕之后的DML和DDL SQL语句
   - redolog记录事务发起之后的DML和DDL SQL语句
   - binlog不是循环使用，写满或实例重启后，会生成新的binlog文件；redo log是循环使用，最后一个文件写满后会重新写第一个文件
   - binlog用于数据恢复使用、主从复制搭建；redolog作为异常宕机或故障的数据恢复使用

#### InnoDB三大特性

三大特性让InnoDB存储引擎有了更好的性能和可靠性

1. 插入缓冲 change buffer
   - 影响数据库最主要的性能问题就是I/O，插入缓冲的作用就是把普通索引上的DML操作从随机I/O变成顺序I/O，提高I/O效率
   - 工作原理：先判断插入的普通索引页是否在缓冲池中，如果在就可以直接插入，不在就先放到change buffer中，然后进行change buffer和普通索引的合并操作，可以将多个插入合并到一个操作中，从而提高了普通索引的插入性能
2. 两次写 double write
   - 两次写保证了写入的安全性，防止在MySQL实例发生宕机时，InnoDB发生数据项部分页 写的有问题
   - 若实例宕机，可以先通过副本把原来的页还原出来，再通过redo log进行恢复、重做，这就是double write的作用
3. 自适应哈希索引
   - InnoDB存储引擎有一个机制，可以监控索引的搜索，如果InnoDB注意到查询可以通过建立哈希索引得到优化，那么就会自动完成这件事。
   - 可以通过innodb_adaptive_hash_index参数来控制。默认情况下是开启的

---

### mysql 数据库文件

#### 数据库层面的文件

1. 二进制日志文件binlog
   - 它和redo log一样都用于记录对MySQL数据库真正执行更改的所有DML（insert、update、delete）操作，不包含那些没有修改任何数据的语句，不会记录select、show等这样的语句，若需要记录则需要开启全量日志功能
   - binary log日志的主要功能：
     1. 可以完成主从复制功能

        - 主服务器上所有修改数据的操作都记录到bin log中，通过网络发送给从服务器，从而达到主从同步

     2. 进行恢复操作

        - 通过bin log日志，使用mysql binlog命令，实现基于时间点和位置的恢复操作
2. 慢查询日志文件show log
3. 错误日志error log
4. 中继日志 relay log
   - 主从复制中，从服务器上一个很重要的文件。从服务器I/O线程将主服务器的二进制日志读取过来并记录到从服务器本地文件（relay log）中，然后从服务器上的SQL线程会读取relay-log
     日志的内容并应用到从服务器
5. 全量日志general log
   - 记录MySQL数据库所以操作的SQL语句，默认是关闭的
   - 因为log的量非常大，但是个别情况可以临时开启用于故障检测
6. 进程文件
   - MySQL数据库是一个单进程多线程模型的数据库，实例启动完成后，会将自己唯一进程号记录到自己Pid文件中
7. 表结构文件
   - MySQL8.0之前，以.frm结尾的文件为表结构文件。从MySQL8.0版本开始，frm表的定义文件被消除掉，把文件中的数据都写到了系统表空间，通过利用InnoDB存储引擎实现表DDL语句操作的原子性（在之前版本中是无法实现表DDL语句操作的原子性的，如truncate无法回
8. 审计日志等等

#### 存储引擎层面的文件

在InmoDB存储引擎层面主要分为两种日志，一种是redo日志，另外一种就是undo日志。
InnoDB支持事务，支持MVCC多版本并发控制。InnoDB的多版本是通过使用undo和回滚段来实现的。InnoDB是索引组织表，每行记录都实现了三个隐藏字段：DBROW_ID、DB_TRXID、DB_ROLLPTR。除DB_ROWID外，DBTRX_ID
和DBROLLPTR分别代表每行记录的事务ID和每行记录的回滚指针。InnoDB有一个全局的事务链表，每个事务的开始都会把事务ID放到链表中。DB_ROLL_PTR指针用于指向undo记录，构造多版本。

1. redo log日志文件
   - redo log用于记录事务操作变化，记录的是数据被修改之后的值。前面的章节中已经介绍它的工作方式：刷新机制
2. undo log日志文件
   - 对记录做变更操作时不仅会产生redo记录，也会产生undo 记录（insert、update、delete）。但undo只记录变更前的旧数据，undo记录默认被记录到系统表空间（ibdatal）中，但是从MySQL5.6开始，就可以使用独立的undo表空间了。采用独立undo表空间，再也不用担心undo会把ibdatal文件弄大；也给我们部署不同I/O类型的文件位置带来便利，对于并发写入型负载，我们可以把undo文件部署到单独的高速存储设备上





---

### 数据库范式

构造数据库必须遵循一定的规则，在关系数据库中，这种规则就是范式。关系数据库中的关系必须满足一定的要求，即满足不同的范式

1NF：属性不可分，即：数据库表的每一列都是不可再分割的基本数据项

2NF：符合1NF，并且每一个非主属性完全依赖于码(候选码、主码都称为码)。即：要求数据库表中的每个实例或行必须可以被唯一区分。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。这个唯一属性列被称为主键

要求

- 满足1NF
- 表必须有一个主键
- 对于没有包含主键的列(非主键的其他列)必须完全依赖于全部主键，而不能依赖于主键的一部分(部分主键)

3NF：非主属性既不传递依赖于码，也不部分依赖于码。3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。像：a-->b-->c  属性之间含有这样的关系，是不符合3NF的。

3NF：在1NF基础上，除了主键以外的其它列都不传递依赖于主键列，或者说： 任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）

要求

- 满足2NF
- 非主键列必须直接依赖于主键，不能存储在传递依赖。即：不能存在非主键列A依赖于非主键列B，非主键B依赖于主键的情况



---

### mysql数据类型

MySQL数据类型大致分为5类，整数类型、浮点数类型和定点数类型、日期和时间类型、字符串类型、二进制类型

#### 整数类型

| 类型名称  | 说明           | 存储需求 |
| --------- | -------------- | -------- |
| tinyInt   | 很小的整数     | 1个字节  |
| smallInt  | 小的整数       | 2个字节  |
| MediumInt | 中等大小的整数 | 3个字节  |
| Int       | 普通大小的整数 | 4个字节  |
| bigInt    | 大整数         | 8个字节  |

#### 浮点数类型\定点数

| 类型名称          | 说明               | 存储需求   |
| ----------------- | ------------------ | ---------- |
| float             | 单精度浮点数       | 4 个字节   |
| double            | 双精度浮点数       | 8个字节    |
| decimal(M,D)，dec | 压缩的“严格”定点数 | M+2 个字节 |

1. double 实际上是以字符串的形式存放的，decimal 可能的最大取值范围与 DOUBLE 相同，但是有效的取值范围由 M 和 D 决定。如果改变 M 而固定 D，则取值范围将随 M 的变大而变大。
2. 从上表中可以看到，DECIMAL 的存储空间并不是固定的，而由精度值 M 决定，占用 M+2 个字节。  

#### 日期/时间类型

| 类型名称  | 日期格式            | 日期范围                                          | 存储需求 |
| --------- | ------------------- | ------------------------------------------------- | -------- |
| year      | YYYY                | 1901 ~ 2155                                       | 1 个字节 |
| time      | HH:MM:SS            | -838:59:59 ~ 838:59:59                            | 3 个字节 |
| date      | YYYY-MM-DD          | 1000-01-01 ~ 9999-12-3                            | 3 个字节 |
| dateTime  | YYYY-MM-DD HH:MM:SS | 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59         | 8 个字节 |
| timeStamp | YYYY-MM-DD HH:MM:SS | 1970-01-01 00:00:01 UTC ~ 2040-01-19 03:14:07 UTC | 4 个字节 |



#### 字符串类型

char、varchar、tinyText、text、mediumText、longText、enmu、set

#### 二进制类型

bit、binary、varBinary、tinyBlob、blob、mediumBlob、longBlob



#### 选择优化的数据类型

1. 更小的通常更好
   - 因为它们占用更少的磁盘、内存、cpu等
2. 简单就好
   - 例如使用整形来存储Ip，把ip转换为32为的数字来存储
3. 避免使用NULL
4. 分配真正需要的大小空间
   - varchar(5)、varchar(200)来存储hello
   - 它们的空间开销是一样的，但是varchar(200)会消耗更多的内存





---

### 视图

#### 什么是视图

视图：本质是一种虚拟表，在物理上不存在的，其内容与真实的表相似，包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值存在。行和列数据来自定义视图的查询所引用的基本表，并且在具体引用视图时动态生成。

#### 为什么使用视图

为了提高复杂SQL语句的复用性和表操作的安全性

视图使得开发者只关心感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，从而提高了数据库中数据的安全性

#### 视图的特点

1. 视图的列可以来自不同的表
2. 视图是由基本表产生的虚表
3. 视图的建立和删除不影响基表
4. 对视图的更新(添加、删除、修改)直接影响基表。由于视图是虚表，所有对视图的更新操作实际上是对其基本的更新操作
5. 当视图来自多个基本表时，不允许添加和删除数据

#### 视图使用场景

1. 重用SQL
2. 简化复杂的sql
3. 保护数据
4. 更改数据格式和表示：视图可返回与底层表的表示和格式不同的数据

#### 创建视图

~~~mysql
create view 视图名 as 子查询 ;

#或者
create or replace view 视图名
~~~





### 存储过程

存储过程是一个预编译的SQL语句。优点是允许模块化的设计，只需要创建一次，以后在程序中就可以调用多次。

如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快

#### 优点

1. 存储过程是预编译过的，执行效率高
2. 存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯
3. 安全性高，执行存储过程需要有一定权限的用户
4. 存储过程可以重复使用，减少数据库开发人员的工作量

#### 缺点

1. 调试麻烦，但是PL/SQL Developer调试很方便，弥补了这个缺点
2. 移植问题，数据库端代码是于数据库相关的。
3. 重编译问题，后端代码运行前需编译，如果带有引用关系的对象发生改变时，受影响的存储过程、包 将需要重新编译



#### 存储过程基础

##### 存储过程结构

1. 基本结构

   存储过程包含三部分：过程声明、执行过程部分、存储过程异常(可写可不写，要增强脚本的容错性和调试的方便性那就写上异常处理)

2. 无参存储过程

   ~~~sql
   create or replace procedure demo as/is
   	变量1 date;
   	变量2 number;
   begin 
   	#要处理的业务逻辑
   	exception  #存储过程异常
   end
   
   
   #demo  代表存储过程名称
   #as/is  任选一个
   ~~~

   

3. 有参存储过程

   ~~~sql
   create or replace procedure demo1Procedure( id int,  name varchar) as 
   age number :=20;
   
   begin 
   	select * from db1 where age=12;
   end;
   ~~~
   
4. 有参存储过程in、out、in out

   ~~~sql
   create or replace procedure 存储过程名称(parm1 in 类型1, parm2 out 类型2)
   
   
   create or replace procedure 存储过程名称(parm1 类型1, parm2 out 类型2)
   
   # 参数默认为in 类型,表示输入参数
   #out 表示返回值参数
   #in out 表示该参数可以向该过程中传递值，也可以将某个值传出去
   ~~~
   


#### 游标

在 MySQL 中，存储过程或函数中的查询有时会返回多条记录，而使用简单的 SELECT 语句，没有办法得到第一行、下一行或前十行的数据，这时可以使用游标来逐条读取查询结果集中的记录

人理解游标就是一个标识，用来标识数据取到了什么地方

MySQL游标只能用于存储过程和函数，存储过程和函数处理完成后，游标就消失了

在存储过程中使用MySQL游标来遍历`SELECT`语句返回的结果集

##### 游标分类

敏感游标：敏感游标指向实际数据。Mysql游标是敏感的

不敏感游标：不敏感游标使用数据的临时副本。敏感游标比一个不敏感的游标执行得更快，因为它不需要临时拷贝数据

##### 声明游标

mysql中使用declare来声明游标，并定义响应的select语句，根据需要添加where和其他子句

~~~mysql
Declare cursor_name Cursor 
For select_statement;
~~~



##### 打开游标

声明游标之后，要想从游标中提取数据，必须首先打开游标。Mysql中通过Open关键字来实现。

打开一个游标时，游标并不指向第一条记录，而是指向第一条记录的前边，一个程序中，一个游标可以打开多次。用户打开游标后，其他用户或程序可能正在更新数据表，所有有时会导致用户每次打开游标后，显示的结果都不同

~~~mysql
open cursor_name;
~~~



##### 使用游标

游标打开后，使用Fetch...Into语句来读取数据

下列语句：将游标中select语句的执行结果保存到参数var_name中，变量参数var_name必须在游标使用之前定义。

使用游标类似数组变量，当第一个使用游标时，此时游标指向结果集的第一条记录

~~~mysql
Fetch cursor_name Into var_name1 [,var_name2]
~~~

Mysql的游标是只读的，也就是说只能顺序地从开始往后读取结果集，不能从后往前，也不能直接跳到中间记录



##### 关闭游标

游标使用完成之后，要及时关闭。一个游标关闭后，如果没有重新打开，则不能使用它。

如果没有手动关闭，Mysql会在到达End语句时会自动关闭它。游标关闭之后，不能使用fetch来使用游标

~~~mysql
Close cursor_name;
~~~



### 函数Function

#### 什么是函数

函数存储着一系列sql语句，调用函数就是一次性执行这些语句。所以函数可以降低语句重复

mysql函数内置很多自定义函数。例如：count、sum等等

#### 自定义函数

自定义函数分为标量值函数和表格值函数

##### 标量值函数

~~~sql
#语法
create [or replace] Function 函数名([parm1,parm2...])
Returns 返回值数据类型
as
begin
	sql语句
	return 变量/值;
end;

#调用函数
select 函数名(参数);
~~~



##### 表格值函数

内联表格值函数

~~~sql
create function 函数名(parm1,parm2...)
returns table
as
return (sql语句)
~~~

多句表格值函数

含义：包含多条sql语句，必须或者至少有一条给表格变量赋值

表格变量格式：returns @变量名(dt)  table(列定义 | 约束定义)

~~~sql
create function 函数名(参数)
returns @dt table (列定义)
as
begin 
	sql语句
end;
~~~



#### 存储过程和函数区别

1. 存储过程不需要返回类型；函数必须返回类型
2. 存储过程用户在数据库中完成特定操作或者任务；函数用于执行任务后返回特定的数据
3. 存储过程的参数可以是in、out、inout类型；函数参数类型只能是in

可以认为存储函数是一个有返回值的存储过程，存储过程是一个没有返回值的存储函数





---

### 表碎片

> 我们有时会在表中删除一些大量的无用数据，但发现数据文件的大小并没有减小，这是因为删除后在数据文件中遗留了大量的数据碎片所导致的

因为使用delete删除数据的时候，MySQL并不会把**数据文件**真实删除，而只是将数据文件的标识位删除，也没有整理数据文件，因此不会彻底释放表空间。换句话说，每当我们从表中删除数据时，这段被删除数据的空间就会被留出来，如果又赶上某段时间内对该表进行大量的delete操作，那么这部分被删除数据的空间就会越来越大。当有新数据写入时，MySQL会再次利用这些被删除的区域，但也无法彻底占用完

所以需要对表进行优化将碎片进行整理

1. 碎片大小=数据总大小-实际表空间大小
2. 数据总大小=data_length+index_length
3. 实际表空间大小：rows*avg_row_length

清理碎片方法

1. alter table table_name engine =innodb 
   - 作用是：重新整理一遍全表数据
   - 缺点：需要给表事先加写锁，时间较长，业务高峰期不建议使用
2. 备份原表数据，然后删掉，重新导入到新表中(与原表结构一样)



---

### MySQL存储引擎与表类型

#### 表类型

1. 表类型由存储引擎决定，主要包括MyISAM、InnoDB、Memory、Csv、archive、mrg_myisam
2. 这类又分为：事务安全型（InnoDB）、非事务安全型(其余都是)



#### 存储引擎

搞懂前两个即可

##### InnoDB

> 是MySQL5.7以后默认的事务型存储引擎

- 优点：支持事务和崩溃修复能力；引入了行锁和外键约束
- 适用于事务支持，并且有较高的并发读写频率



##### MyISAM

- 5.5以前版本默认存储引擎
- 对于只读数据、或表比较小、可以容忍修复操作等可以使用MyISAM存储引擎
- MyISAM会将表存储在两个文件中：数据文件.myd 和索引文件 .myi



##### Memory

- Memory存储引擎将数据全部放在内存中，访问速度快，但是一旦系统崩溃，数据全部丢失
- 默认使用哈希索引，将键的哈希值和指向数据行的指针保存在哈希索引中



##### InnoDB/MyISAM两者区别

1. InnoDB支持行锁和表锁、默认是行锁，MyISAM只支持表锁
2. InnoDB支持事务，MyISAM不支持事务
3. InnoDB支持外键，MyISAM不支持
4. InnoDB支持MVCC，MyISAM不支持。应对高并发事务，MVCC比单纯的加锁更高效
5. InnoDB支持聚集索引，MyISAM不支持聚集索引
   - MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。
   - MyISAM :数据文件 .myd 、索引文件myi、表结构文件.frm
   - InnoDB：数据索引文件 .ibd   (表空间）、 表结构文件.frm

---



### MySQL事务

> MySQL事务默认是隐式事务，执行insert、update、delete操作的时候，数据库自动开启事务、提交或回滚事务



#### 事务四大特性ACID

1. 原子性(Atomicity):一个事务中的所有操作，要么全部完成，要么全部不完成。事务在执行过程中发生错误会被回滚到事务开始前的状态，就像这个事务没有执行过一样
   - undo log保证了原子性
   - 每条数据变更（INSERT/UPDATE/DELETE/REPLACE）等操作都会生成一条undo log记录，在SQL执行前先于数据持久化到磁盘
   - 当事务需要回滚时，MySQL会根据回滚日志对事务中已执行的SQL做逆向操作，比如 DELETE 掉一行数据的逆向操作就是再把这行数据 INSERT回去，其他操作同理
2. 一致性(Consistency):事务开始之前和事务结束之后，数据库的完整性没有被破坏。
   - 通过原子性、隔离性、持久性最终实现数据一致性
3. 隔离性(Isolation):数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致
   - 读写锁+Mvcc实现
4. 持久性(Durability):事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失
   - binlog、redo log实现



#### 并发事务处理带来的问题

##### 脏读

一个事务读取到另一个事务未提交的数据。当前事务正在访问数据并且进行了修改，但是这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个修改的数据

![image-20220325165637236](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220325165637236.png)

##### 不可重复读

一个事务对同一行数据重复读取两次，但得到的结果不同

一个事务内，多次读取同一数据。在这个事务还没有结束时，另外一个事务也访问同一数据。那么在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读

这就涉及到：隔离级别下 mvcc架构中read view的生成时机

![image-20220325165624391](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220325165624391.png)

##### 幻读

一个事务执行两次查询，但第二次查询的结果包含了第一次查询中未出现的数据。

例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。

MySQL通过间隙锁+行锁 =>临键锁解决了这个问题

![image-20220325165605236](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220325165605236.png)



##### 丢失更新

> 两个事务同时更新一行数据，后提交(或撤销)的事务将之前事务提交的数据覆盖了

###### 第一类丢失更新（回滚丢失）

指两个事务同时操作同一个数据时，当第一个事务撤销时，把已经提交的第二个事务的更新数据覆盖了，第二个事务就造成了数据丢失

![image-20220912202937245](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202209122029398.png)

###### 第二类丢失更新（覆盖丢失/两次更新问题）

指两个事务同时操作同一个数据时，第一个事务将修改结果成功提交后，对第二个事务已经提交的修改结果进行了覆盖，对第二个事务造成了数据丢失

![image-20220325171513602](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220325171513602.png)

###### 如何避免丢失更新的发生

- 锁机制防止丢失更新

- 行级排它锁解决

  

为了解决上述事务并发问题的出现，SQL规范中定义了四种隔离级别，不同隔离级别对事务的处理有所不同

#### 事务的隔离级别

作用：让并发的事务相互隔离，互不影响，这样可以保证事务的一致性

1. 读未提交：事务AB，对于B来说，事务A未提交的变更数据，事务B可以读取到
2. 读已提交：事务AB，A事务提交之后的数据，当前B事务才能读取其他事务做的变更。Oracle默认隔离级别
3. 可重复读：事务AB，事务A提交之后的数据，事务B读取不到。一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。(mvcc实现的又叫快照读)
   当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的
   - 例如AB事务同时启动了，A查询name=qc，B查询name=qc
   - 此时A将name改为qc2，并提交事务
   - 此时A再去查询name时候，还是name=qc
4. 串行化：事务AB，mysql在同一时刻只允许单个事务执行，事务A在操作数据库时，事务B只能排队等待

| 隔离级别类型             | 脏读 | 不可重复读 | 幻读 |
| ------------------------ | ---- | ---------- | ---- |
| 读未提交Read uncommitted | 会   | 会         | 会   |
| 读已提交read committed   | 不会 | 会         | 会   |
| 可重复读 repeatable read | 不会 | 不会       | 会   |
| 序列化Serializable       | 不会 | 不会       | 不会 |



#### 如何解决这些问题

##### 锁机制

数据库通过锁机制解决并发访问的问题，MySQL事务隔离依靠锁来实现的，加锁自然会带来性能的损失。但是读未提交隔离级别是不加锁的，所以他的性能最好。但是会造成连脏读都没有办法解决

1. 根据锁对象不同分为：
   - 行级锁：锁定当前数据行，锁的粒度小、加锁慢，发生锁冲突概率小，并发度高。InnoDB支持行锁和事务、MyISAM这两者都不支持。**mysql行级锁是加在索引上的**
   - 为了更改数据，数据库必须在进行更改的行上施加独占锁，insert、update、delete、select for update语句会隐式的采用行锁定
   - 表级锁：锁的粒度大，加锁快，开销小，但是锁冲突的概率大，并发度低
   
2. 根据并发事务锁定的关系上看：
   - 共享锁：针对同一份数据，多个读操作可以同时进行，但是不能写操作
   - 独占锁：针对写操作，假如当前写操作没有完成，那么它会阻断其他的写锁和读锁，即：写加锁，其他读写都阻塞
   
   

为什么上了写锁，别的事务还可以读操作？==》MVCC机制，使用快照读，不会被阻塞

**读未提交加锁情况**：没加锁

**串行化加锁情况**：读的时候加的共享锁，也就是其他事务可以并发读取，但是不能写。写的时候加的排它锁(写锁、独占锁、X锁)，其他事务不能并发读和写

**读已提交加锁情况**：他们俩的底层实现采用的是MVCC（多版本并发控制）方式进行实现

**可重复读加锁情况**：他们俩的底层实现采用的是MVCC（多版本并发控制）方式进行实现



#### Innodb如何解决幻读

MySQL存储引擎InnoDB在可重复的隔离级别下，是解决了幻读问题的

解决方法：通过临键锁(next-key lock)在当前事务开启时，首先给涉及到的行加锁防止写操作，其次通过给涉及到的行两端加间隙锁(Gap lock)防止新增行写入；从而解决了幻读问题

~~~sql
mysql> select * from LOL;
+----+--------------+--------------+-------+
| id | hero_title   | hero_name    | price |
+----+--------------+--------------+-------+
|  1 | 刀锋之影     | 泰隆         |  6300 |
|  2 | 迅捷斥候     | 提莫         |  6300 |
|  3 | 光辉女郎     | 拉克丝       |  1350 |
|  4 | 发条魔灵     | 奥莉安娜     |  6300 |
|  5 | 至高之拳     | 李青         |  6300 |
|  6 | 无极剑圣     | 易           |   450 |
|  7 | 疾风剑豪     | 亚索         |  6300 |
+----+--------------+--------------+-------+
7 rows in set (0.00 sec)
~~~



![image-20220325134120755](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220325134120755.png)

1. Q1 只返回 "无极剑圣" 这一行；
2. 在 T2 时刻，session B 把 "疾风剑豪" 这一行的 price 值改成了 450，因此 T3 时刻 Q2 查出来的是 "无极剑圣" 和 "疾风剑豪" 这两行；
3. 在 T4 时刻，session C 又插入一行 (10,'雪人骑士','努努','450')，因此 T5 时刻 Q3 查出来 price = 450 的是"无极剑圣" 、"疾风剑豪" 和 "雪人骑士" 这三行。

其中，Q3 读到 (10,'雪人骑士',450) 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行





那么幻读能仅通过行锁解决么？

答案是否定的。如上面示例，`select xx for update（当前读  mysql会加入next-lock）`是将所有条件涉及到的（符合where条件）行加上行锁。但是，就算在select xx for update 事务开启时将所有的行都加上行锁，也锁不住Session C新增的行，因为在我给数据加锁的时刻，压根就还没有新增的那行，自然也不会给新增行加上锁

所以要解决幻读，必须得解决新增行的问题！

产生幻读的原因是：**行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”**。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)

比如表 LOL，初始化插入了 7 个记录，这就产生了 8 个间隙。

![image-20220325135414075](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220325135414075.png)



next-key lock

当执行 select * from LOL where hero_title = '疾风剑豪' for update 的时候，就不止是给数据库中已有的 7 个记录加上了行锁，还同时加了 8 个间隙锁。这样就确保了无法再插入新的记录，也就是Session C在T4新增(10,'雪人骑士','努努','450') 行时，由于ID大于7，被间隙锁（7，+∞）锁住。

  在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。MySQL将行锁 + 间隙锁组合统称为 next-key lock，通过 next-key lock 解决了幻读问题。

**作用**：

- 防止间隙中执行insert
- 防止将已有数据update到间隙中

**注意：**  next-key lock的确是解决了幻读问题，但是next-key lock在并发情况下也经常会造成死锁。死锁检测和处理也会花费时间，一定程度上影响到并发量



---



### MVCC实现原理

> MVCC：Multiversion concurrency control 多版本并发控制，主要是为了提高数据库并发性能，对于高并发场景，MVCC比行级锁开销更小。
>
> MVCC是维持一个数据的多个版本，使读(快照读)写操作没有冲突的一个抽象概念，快照读是MySQL实现MVCC模型的其中一个非阻塞读功能
>
> 就是同一份数据保留多版本的一种方式，进而实现并发控制。在查询的时候，通过read view和版本链找到对应版本的数据。

[参考链接1](https://www.php.cn/mysql-tutorials-460111.html)

[参考链接2](https://blog.csdn.net/SnailMann/article/details/94724197?utm_source=app&app_version=5.0.0)



#### 当前读和快照读

###### 当前读

例如：select * from xxx   lock in share mode(共享锁)，select for update，update、insert、delete(排他锁)、串行化事务隔离级别，这些操作都是一种当前读

为什么叫当前读：它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对当前读取的记录进行加锁



###### 快照读

> 例如：普通的不加锁的select操作就是快照读，即不加锁的非阻塞读；
>
> 快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读

之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC ,可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销。既然是基于多版本的，那么，快照读可能读到的并不一定是数据的最新版本，有可能是之前的历史版本



**MVCC与快照读的关系**

MVCC是维持一个数据的多个版本，使得读写操作没有冲突的一个**抽象概念**，这个概念需要具体功能实现就是快照读



#### 数据库高并发场景

1. 读-读：不存在任何问题，也不需要并发控制
2. 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
3. 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

**MVCC就是为了实现  读-写 冲突不加锁**，而这个读是快照读，而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现



#### MVCC解决哪些并发问题

mvcc用来解决**读—写冲突的无锁并发控制**，就是为事务分配单向增长的时间戳。为每个数据修改保存一个版本，版本与事务时间戳相关联。

1. 并发 读-写时：可以做到读操作不阻塞写操作，写操作不阻塞读操作；提高了数据库的并发读写的性能
2. 解决了脏读、幻读、不可重复读等事务隔离问题。但是**不能解决写-写 更新丢失问题**



有了MVCC后，因此出现了提高并发性能的组合：可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题

MVCC+悲观锁：mvcc解决读写冲突，悲观锁解决写写冲突

MVCC+乐观锁mvcc解决读写冲突，乐观锁解决写写冲突



#### 实现原理

> MVCC依赖于版本链、undo log、read view以及记录中的4个隐式字段来实现



##### 隐式字段

数据库中的每行数据，除了肉眼可见的数据，还有一些隐藏字段。版本链是通过表的三个隐藏字段实现

1. db_trx_id：表示最后一次修改/修改的事务id，通过事务id的大小判断事务的时间顺序

2. db_roll_prt：(pointer) 回滚指针，指向当前行记录的上一个版本，通过这个指针将数据的多个版本连接在一起构成undo log版本链

3. db_row_id：隐含的自增ID(隐藏主键)，如果数据表没有主键，Innodb会自动以db_row_id产生一个聚集索引

4. 此外，delete操作在内部视为更新

   - record header：只会在记录头中的deleted_flag字段标记为已删除

     

每条记录大概是这样的

| name | age  | DB_ROW_ID(隐式Id) | DB_TRX_ID | DB_ROLL_PTR |
| ---- | ---- | ----------------- | --------- | ----------- |
| YHC  | 25   | 1                 | 1         | 0x23333     |

​	

##### undo log

undo log主要用于**记录数据被修改之前的日志**，在表信息修改之前，会先把数据拷贝到undo log中。当事务进行回滚时，可以通过undo log日志进行数据回滚

###### undo log主要用途

1. 保证事务进行`rollback`时的`原子性和一致性`，当事务进行`回滚`的时候可以用undo log的数据进行`恢复`
2. 用于MVCC快照读的数据，在MVCC中通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本

###### undo log分类

1. insert undo log
   - 代表事务在insert新的记录时产生的undo log日志，只在事务回滚时需要，并且在事务提交后可以被立即丢弃
   - 插入一条记录时，至少要把这条记录的主键值记下来，之后回滚的时候只需要把这个主键值对应的记录删掉就好了
2. update undo log（主要）
   - 修改一条记录时，至少要把修改这条记录前的旧值都记录下来，这样之后回滚时再把这条记录更新为旧值就好了
   - 事务在进行update或delete时产生的undo log；不仅在事务回滚时需要，在快照读时也需要；所有不能随便删除，只有在快照读或事务回滚不涉及该日志时，对应的日志才被purge线程统一清除
3. delete undo log
   - 删除一条记录时，至少要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了



##### 版本链

> 版本链的头节点就是当前记录的最新值



使用事务更新行记录的时候，就会生成版本链，执行过程：

1. 用排他锁锁住该行
2. 将该行原本的值拷贝到undo log，作为旧版本用于回滚
3. 修改当前行的值，生成一个新的版本，更新事务id，使 回滚指针指向旧版本记录，这一就形成一条版本链

![image-20220324133558317](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220324133558317.png)

例如：

初始数据如下，其中假设DB_TRX_ID和DB_POLL_PTR为null

![image-20220327222959052](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202203272229184.png)

事务1 对该行做修改时，先对该行加排他锁，然后把改行拷贝到undo log中，拷贝完成后修改name为Tom，同时修改隐藏字段事务id默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，事务提交后释放锁

![image-20220327222930982](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202203272229183.png)

之后事务2也对该记录做了修改，将age改为30，同事务1进行同样的操作

![image-20220327223050366](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202203272230508.png)																																															 

从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表，既链表，undo log 的链首就是最新的旧记录，链尾就是最早的旧记录（当然就像之前说的该 undo log 的节点可能是会 purge 线程清除掉，向图中的第一条 insert undo log，其实在事务提交之后可能就被删除丢失了，不过这里为了演示，所以还放在这里)



##### read view(读视图)

read view了实现快照读，说白了就是事务进行快照读操作的时候产生的读视图，在该事务执行快照读那一刻，会生成数据库系统当前的一个快照，并记录和维护当前系统活跃事务的id（没有commit的，当开启事务时，都会被分配一个id，这个id是递增的，所以越新的事务，ID值越大)。通过这个列表来判断记录的某个版本是否对当前事务可见



read view的作用：主要用来做**版本可见性判断**，当某个事务执行快照读的时候，对该记录创建一个reda view，把它作为条件用来判断当前事务能够看到哪个版本的数据，即：可能是当前最新的数据，也可能是该行记录的undo log里面的某个版本的数据



read view遵循一个可见性算法，主要是：把要被修改数据的最新记录中的DB_TRX_ID取出来（即当前事务id），与系统中当前活跃的事务的id去对比(这个有read view维护)，如果DB_TRX_ID跟read view的属性做了某些比较，不符合可见性，那就通过DB_POLL_PTR回滚指针去取undo log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID，直到找到满足特定条件的DB_TRX_ID，那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新的老版本

###### read view几个属性

1. trx_ids：当前系统活跃(未提交)事务id列表
2. low_limit_id：创建当前read view时，系统尚未分配的下一个事务 ID ，即：目前已出现过的事务ID的最大值 + 1 ，当前系统最大事务id+1
3. up_limit_id：创建当前read view时，trx_ids中事务id最小的id
4. creator_trx_id：创建当前read view的事务id

###### read view可见性判断条件

![image-20220327224520607](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202203272245831.png)

1. 显示：db_trx_id<up_limit_id || db_trx_id == creator_trx_id 
   - 如果当前事务ID小于read view中最小活跃事务ID，则可以肯定该数据是在当前事务开启之前就已经存在了，所有可以显示
   - 或者当前事务ID等于creator_trx_id，那么说明这个数据就是当前事务自己生成的，自己生成当然可见
2. 不显示：db_trx_id>=low_limit_id
   - 当前事务ID，大于read view中当前系统的最大事务Id，则说明该数据是在read view创建之后产生的，所以不显示。如果小于则进入下一个判断
3. db_trx_id是否在活跃事务(trx_ids)中
   - 不在：则说明read view产生的时候，事务已经commit了，这种情况则可以显示
   - 存在：说明 我read view生成时刻，你这个事务还在活跃，还没有commit，你修改的数据，我当前事务看不见的

##### 整体流程

当事务 2对某行数据执行了快照读，数据库为该行数据生成一个Read View读视图，假设当前事务 ID 为 2，此时还有事务1和事务3在活跃中，事务 4在事务 2快照读前一刻提交更新了，所以 Read View 记录了系统当前活跃事务 1，3 的 ID，维护在一个列表上，假设我们称为trx_list

| 事务 1   | 事务 2   | 事务 3   | 事务 4       |
| -------- | -------- | -------- | ------------ |
| 事务开始 | 事务开始 | 事务开始 | 事务开始     |
| …        | …        | …        | 修改且已提交 |
| 进行中   | 快照读   | 进行中   |              |
| …        | …        | …        |              |

Read View 不仅仅会通过一个列表 trx_list 来维护事务 2执行快照读那刻系统正活跃的事务 ID 列表，还会有两个属性 up_limit_id（ trx_list 列表中事务 ID 最小的 ID ），low_limit_id ( 快照读时刻系统尚未分配的下一个事务 ID ，也就是目前已出现过的事务ID的最大值 + 1 ) 。所以在这里例子中 up_limit_id 就是1，low_limit_id 就是 4 + 1 = 5，trx_list 集合的值是 1, 3，Read View 如下图
![image-20220327231420016](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202203272314175.png)

我们的例子中，只有事务 4 修改过该行记录，并在事务 2 执行快照读前，就提交了事务，所以当前该行当前数据的 undo log 如下图所示；我们的事务 2 在快照读该行记录的时候，就会拿该行记录的 DB_TRX_ID 去跟 up_limit_id , low_limit_id 和活跃事务 ID 列表( trx_list )进行比较，判断当前事务 2能看到该记录的版本是哪个、

![image-20220327231707332](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202203272317449.png)

所以先拿该记录 DB_TRX_ID 字段记录的事务 ID 4 去跟 Read View 的 up_limit_id 比较，看 4 是否小于 up_limit_id( 1 )，所以不符合条件，继续判断 4 是否大于等于 low_limit_id( 5 )，也不符合条件，最后判断 4 是否处于 trx_list 中的活跃事务, 最后发现事务 ID 为 4 的事务不在当前活跃事务列表中, 符合可见性条件，所以事务 4修改后提交的最新结果对事务 2 快照读时是可见的，所以事务 2 能读到的最新数据记录是事务4所提交的版本，而事务4提交的版本也是全局角度上最新的版本

![生成readview时机](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202203272317353.png)



#### MVCC相关问题

在RR、RC隔离级别下，生成Read View的时机是不同的，从而造成快照读的结果不同



###### RR 是如何在 RC 级的基础上解决不可重复读的？

表1：当前读和快照读在 RR 级别下的区别：

| 事务A                       | 事务B                                      |
| --------------------------- | ------------------------------------------ |
| 开启事务                    | 开启事务                                   |
| 快照读(无影响)查询金额为500 | 快照读查询金额为500                        |
| 更新金额为400               |                                            |
| 提交事务                    |                                            |
|                             | select `快照读`金额为500                   |
|                             | select lock in share mode`当前读`金额为400 |

在上表的顺序下，事务 B 的在事务 A 提交修改后的快照读是旧版本数据，而当前读是实时新数据 400



表2

| 事务A                         | 事务B                                      |
| ----------------------------- | ------------------------------------------ |
| 开启事务                      | 开启事务                                   |
| 快照读（无影响）查询金额为500 |                                            |
| 更新金额为400                 |                                            |
| 提交事务                      |                                            |
|                               | select `快照读`金额为400                   |
|                               | select lock in share mode`当前读`金额为400 |

表 2这里的顺序中，事务 B 在事务 A 提交后的快照读和当前读都是实时的新数据 400，这是为什么呢？

- 这里与上表的唯一区别仅仅是`表 1`的事务 B 在事务 A 修改金额前`快照读`过一次金额数据，而`表 2`的事务B在事务A修改金额前没有进行过快照读



所以：事务中快照读的结果是非常依赖**该事务首次出现快照读的地方**，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力

我们这里测试的是`更新`，同时`删除`和`更新`也是一样的，如果事务B的快照读是在事务A操作之后进行的，事务B的快照读也是能读取到最新的数据的



#### MVCC和事务隔离级别

> read view用于支持RC和RR隔离级别的实现



RR、RC生成read view时机：

1. RC隔离级别下，每个快照读都会生成并获取最新的Read View
2. RR隔离级别下，则是同一个事务中的第一个快照读才会创建read view，之后的快照读获取的都是同一个read view，之后的查询就不会重复生成read view了，所以一个事务中的查询结果每次都是一样的

解决幻读问题：

1. 快照读：通过MVCC控制，不用加锁。按照MVCC中规定的“语法”进行增删改查等操作，以避免幻读
2. 当前读：通过临键锁(next-key)来解决 即：行锁+间隙锁(gap)

####  RC , RR 级别下 InnoDB快照读区别

正是 Read View 生成时机的不同，从而造成 RC , RR 级别下快照读的结果的不同

1. 在 RR 级别下的某个事务的对某条记录的第一次快照读会创建一个快照及 Read View，将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个 Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个 Read View，所以对之后的修改不可见；即：RR 级别下，快照读生成 Read View 时，Read View 会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见
2. 而在 RC 级别下的，每个事务中，每次快照读都会新生成一个快照和 Read View , 这就是我们在 RC 级别下的事务中可以看到别的事务提交的更新的原因

#### 总结

InnoDB的MVCC通过read view 和版本链实现，版本链保存有历史版本记录，通过read view 判断当前版本的数据是否可见，如果不可见，再从版本链中找到上一个版本，继续进行判断，直到找到一个可见的版本。

所谓的MVCC指的就是在使用`READ COMMITTD`、`REPEATABLE READ`这两种隔离级别的事务在执行普通的`SEELCT`操作时访问记录的`版本链`的过程，这样子可以使不同事务的`读-写`、`写-读`操作`并发执行`，从而`提升系统性能`

---



### MySQL分库分表

#### 水平切分

1. 水平切分又叫：Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。
2. 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力。
3. ![image-20220315211326794](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152113604.png)

#### 垂直切分

1. 垂直切分是将一张表切分成多个表，通常按照列的关系密集程度进行切分，也可以将经常使用的列和不经常使用的列切分到不同的表中
2. 在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等

#### Sharding策略

1. 哈希取模：hash(key)%Num_Db
2. 范围:可以是ID范围，也可以是时间范围
3. 映射表：使用单独的一个数据库来存储映射关系

---



### MySQL分区

参考：

https://www.cnblogs.com/helios-fz/p/13671682.html

https://juejin.cn/post/6844903991944413191

#### 概念

1. 将同一表中，不同行的记录分配到不同的物理文件中，几个分区就有几个.ibd文件(InnoDB引擎)。（MyISAM引擎生成.myd 和.myi文件）
2. 分区是将一个表或索引分解成多个更小、更可管理的部分。每个分区都是独立的，可以独立处理，亦可以作为一个更大对象的一部分进行处理
3. MySQL数据库的分区是局部分区索引，一个分区中既存了数据，又放了索引，也就是说，每个区的聚集索引和非聚集索引都放在各自区的(不同的物理文件)。目前MySQL不支持全局分区

#### MySQL分区表

分区表是一个独立的逻辑表，但是底层由多个物理子表组成。

MySQL实现分区的方式：对底层表的封装，意味着索引也是按照分区的子表定义的，没有全局索引。这个Oracle不同，在Oracle中可以更加灵活地定义索引表和表是否进行分区。

查询时，优化器会根据分区定义过滤掉那些没有在我们需要数据的分区，这样查询无需扫描所有分区，只需要查询包含需要数据的分区就可以了

分区主要目的：将数据按照一个较粗的粒度划分到不同的表中

以下场景中，分区可以起到非常大的作用：

1. 表非常大以至于无法全部放在内存中，或只需要表里面的热点数据，其他均为历史数据
2. 分区表的数据更容易维护，例如：想批量删除整个分区的数据，另外还可以对分区进行优化、检查、修复等等操作
3. 分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备

#### 分区类型

以下几种：无论哪种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分

查看执行计划，和普通的执行计划比较多了partitions、filtered字段，partitions标识走了哪几个分区

explain partitions select 语句；

##### Range分区

1. 是实战中最为常用的一种分区类型，行数据基于属于一个给定的连续区间的列值被放入分区。但是，当插入的数据不再一个分区中定义的值的时候，会抛异常

2. ~~~mysql
   CREATE TABLE `m_test_db`.`Order` (
       `id` INT NOT NULL AUTO_INCREMENT,
       `partition_key` INT NOT NULL,
       `amt` DECIMAL(5) NULL,
       PRIMARY KEY (`id` , `partition_key`)
   ) PARTITION BY RANGE (partition_key) PARTITIONS 5 (
   PARTITION part0 VALUES LESS THAN (201901) , 
   PARTITION part1 VALUES LESS THAN (201902) , 
   PARTITION part2 VALUES LESS THAN (201903) , 
   PARTITION part3 VALUES LESS THAN (201904) , 
   PARTITION part4 VALUES LESS THAN (201905));
   #插入数据
   INSERT INTO `m_test_db`.`Order` (`id`, `partition_key`, `amt`) VALUES ('1', '201901', '1000');
   INSERT INTO `m_test_db`.`Order` (`id`, `partition_key`, `amt`) VALUES ('2', '201902', '800');
   INSERT INTO `m_test_db`.`Order` (`id`, `partition_key`, `amt`) VALUES ('3', '201903', '1200');
   
   ~~~

   - ~~~mysql
     explain partitions select * from order where partition_key ='201902'
     #可以看出，SQL优化器只搜索对应的part2分区
     ~~~

   - |      |             |       |            |       |               |      |         |      |      |          |       |
     | ---- | ----------- | ----- | ---------- | ----- | ------------- | ---- | ------- | ---- | ---- | -------- | ----- |
     | id   | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
     | 1    | Simple      | order | part2      | index |               |      |         |      |      |          |       |

注意事项：

1. MySQL分区表如果有主键，那么必须包含分区字段，所以创建语句是一个复合主键，否则会报SQL创建表错误
2. 对于原生分区，分区对象返回的只能是整数值
3. 分区字段不能为null

以下几种分区不常用：

##### List分区

LIST分区和RANGE分区很相似，只是分区列的值是离散的，不是连续的。LIST分区使用VALUES IN，因为每个分区的值是离散的，因此只能定义值

##### Hash分区

将数据均匀的分布到预先定义的各个分区中，以保证每个分区的熟练大致相同

##### Key分区

KEY分区和HASH分区相似，不同之处在于HASH分区使用用户定义的函数进行分区，KEY分区使用数据库提供的函数进行分区



##### MySQL分区过滤失效

1. Null值会使分区过滤无效，5.5已经解决这个问题了
2. 分区列和索引列不匹配



---



### MySQL备份

#### 备份分类

##### 物理备份

1. 物理备份：对数据库操作系统的物理文件(如：数据文件、日志文件)
2. 冷备份(脱机备份)：关闭数据库的时候进行的
3. 热备份(联机备份)：数据库处于运行状态，依赖于数据库的日志文件
4. 温备份：数据库锁定表格(不可写入但可读)的状态下进行备份操作

##### 逻辑备份

所谓逻辑备份就是备份SQL语句，在恢复时执行备份SQL从而实现数据库数据的重现

1. mysqldump：mysql数据库自带的命令工具
2. select ..into outfile
3. mydumper
4. 等等

#### 常用备份方法

1. 物理备份
2. 专用备份工具
   - mysqldump:常用
   - mysqlhotcopy：仅拥有备份MyISAM和Archive表类型
3. 启动二进制日志进行增量备份
   - 进行增量备份，需要刷新二进制日志
4. 第三方工具备份
   - MySQL免费热备份软件 Percona XtraBackUp



#### 完全备份

对整个数据库进行备份、数据库结构和文件结构的备份



---





### 索引

> MySQL的索引是在**存储引擎层实现的**，所以不同存储引擎具有不同的索引类型和实现。



#### 磁盘相关知识

1. 系统从磁盘读取数据到内存时，是以“磁盘块”为基本单位的，位于同一磁盘块中的数据会被一次性读取出来，而不是需要什么取什么

2. InnoDB存储引擎中，有“页”的概念，页是磁盘管理的最小单位。InnoDB存储引擎中默认每个页的大小为16kb，可通过参数innodb_page_size将页大小设置为4k、8、16k

   ~~~mysql
   #查看 页 大小命令
   mysql> show variables like 'innodb_page_size'   ==》16384
   ~~~

3. 然而系统一个磁盘块的存储空间往往没有这么大，因此InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。InnoDB在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率

   - 数据库系统将索引的一个节点的大小设置为页的大小，使得一次I/O就能完全载入一个节点，并且可以利用预读的特性，相邻的节点能够被预先载入





#### MySQL索引分类



##### 按照数据的物理存储方式分类

- 聚集索引
- 非聚集索引(辅助索引、二级索引)
- 两个索引的区别：聚集索引一张表只能有一个，然而非聚集索引一张表可以有多个

##### 应用层次

1. 单列索引
   - 主键索引
   - 普通索引
     - 建立在普通字段上的索引，没有限制
   - 唯一索引
     - 建立在唯一字段（该字段的值是唯一的）上的索引，一张表可以有多个唯一索引，唯一索引列允许为空
     - 和普通索引基本类似，不过唯一索引所在列的值必须唯一，可以为null值，列值中出现多个空值不会发生重复冲突
2. 组合（联合、复合）索引
   - 多个字段上创建的索引
   - 使用组合索引时，遵循最左前缀集合
   - 例如：index (a,b,c) 那么 索引支持a | a、b | abc 这三种组合进行查找，但是不支持b | c | b、c 这样的查找，必须按照索引字段创建的顺序来

##### 索引的数据结构分

https://www.cnblogs.com/xiaoxi/p/6894610.html

1. B树索引

   - B树  balance平衡


   - 一种用于查找的平衡树，但是不是二叉树，是平衡多路查找树


   - 能够用来存储排序后的数据


   - 性质

     - B树的阶：子节点数目的最大值


     - 每个节点中，包含数据的关键字key、数据Data、指向子节点的指针，通过key就能得到数据


​       

2. B+树索引

   - B树上做的优化

   - InnoDB存储引擎用B+树，实现的索引

   - **所有数据记录在叶子节点上**，其数值是按照key的大小顺序存放在同一层的叶子节点上，非叶子节点只存放key值信息，这样大大加大每个节点存储key的数量，降低了B+tree 的高度

   - 所有叶子节点之间有一个链指针

   - 索引定位数据：查询到B+树叶子节点后，遍历叶子节点的数据页，从而找出该条记录

     

3. 全文索引(Full-text)

   - 通过关键字的匹配来进行查询过滤=》基于相似度的查询


   - 它查找的是文本中的关键词，而不是直接比较索引中的值。类似于搜索引擎做的事情，而不是讲的的where条件匹配

     




#### InnoDB的索引类型

> InnoDB的数据文件本身就是索引文件！InnoDB的数据和索引是放在一起的



##### B+树索引

> 使用索引后，不需要进行全表扫描，只需要对索引树进行搜索即可，因此查找速度很快。另外，除了用于查找，还能应用于排序和分组。因为B+tree是有序的
>
> 分组的实质是先排序、再分组



1. InnoDB的B+树索引分为：主索引（聚簇索引）和辅助索引（非聚簇索引）

2. 主索引：

   - 以主键作为B+树索引的键值所构成的B+树索引，叶子节点data域记录着完整的数据记录，这种索引方式被称为**聚簇索引**，因为无法把数据行存放在两个不同的地方（InnoDB的数据文件本身就是索引文件），所以一个表只有一个聚簇索引。图中：数字代表主键值

   - ![](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/20220311150916.png))

     

3. 辅助索引：叶子节点data域记录着主键的值，因此使用辅助索引进行查找时，需要先查到主键值，然后再到主索引中进行查找(回表)。单词代表非主键的索引列

   
  
   回表：首先检索辅助索引获取主键，然后用主键到主索引中检索获取记录。通过二级索引查询时，回表不是必须的过程，当SELECT的所有字段在单个二级索引中都能够找到时，就不需要回表，MySQL称此时的二级索引为**覆盖索引**或触发了**索引覆盖**。 可以用Explain命令查看SQL语句的执行计划，执行计划的Extra字段中若出现**Using index**，表示查询触发了索引覆盖
   
   
   
   
   
   ![](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/20220311151051.png)
   
   
   
   
   
   
   
4. 为什么不建议使用过长字段作主键？

   因为Innodb引擎中：所有的辅助索引都会引用主键，过长的主键会导致辅助索引过大
   
   

##### B+树比B树更适合做文件索引的原因

1. 结构上：B树中关键字分布在整颗树中，叶节点不包含任何关键字信息，而B+tree关键字分布在叶子节点中，非叶子节点只是叶子节点中关键字的索引

2. B+树空间利用率更高，可减少I/O次数
   - B+树的**内部结点并没有指向关键字具体信息的指针**，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素
   
   

##### 前缀索引

对于Varchar、Blob、Text类型的列，必须使用前缀索引。不过，对于前缀长度的选择，需要根据索引选择性来确定（不重复的索引值/总数），选择性越接近1越好

例如：create index email_index(email(6)) 就是根据email的前6个字符做索引







##### Hash索引

> MySQL中Memory存储引擎默认的索引。能以O(1)的时间复杂度查找，但是失去了有序性

Hash索引基于Hash表实现，对于每一行数据，存储引擎会对索引列通过hash算法进行hash计算得到hash码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码值作为哈希表的key，将指向数据行的**指针**作为哈希表的value值。这样查找一个数据的时间复杂度就是O(1)，一般用于精确查找

![image-20220607141044267](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206071411583.png)

因为hash本身的特性，所以带来了很多限制和弊端

1. Hash索引仅仅能满足：=、In、<=>查询，不能使用范围查询
2. 联合索引中，hash索引不能利用部分索引键查询
3. hash索引无法避免数据的排序操作
4. hash索引任何时候都不能避免表扫描
5. 访问哈希索引的数据非常块，除非有很多哈希冲突，当出现哈希冲突的时候，存储引擎必须遍历链表中索引的行指针，逐行进行比较，直到找到所有符合条件的行

特殊功能：**自适应哈希索引**

InnoDB引擎有一个特殊的功能-自适应哈希索引，当InnoDB注意到某些索引值被使用非常频繁时，它会在内存中基于B-tree索引上再建一个哈希索引，这样就让B-tree索引具有了哈希索引的特点。这是InnoDB一个完全自动的、内部的行为，用户无法控制或配置，不过如果有必要该功能可以关闭

##### 区别

1. 因为两者数据结构上的差异导致它们的使用场景也不同，哈希索引一般多用于精确的等值查找，B+索引则多用于除了精确的等值查找外的其他查找。在大多数情况下，会选择使用B+树索引



#### 联合索引及最左原则

高效使用索引的首要条件是要知道什么样的查询会使用到索引，这个问题和B+Tree的最左前缀原理有关

https://segmentfault.com/a/1190000023617757

表T数据如下：其中，a为主键，b、c、d为一个联合索引

![image-20220329101649047](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/image-20220329101649047.png)

index(b、c、d)联合索引在B+tree上的结构如下：黄色为索引列，紫色为data域这里存的是主键

为什么叶子节点data部分存储的是主键而不是整行记录？因为这是一个非聚簇索引

每一个非叶子节点都会存放所有索引列

![image-20220329102009907](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/image-20220329102009907.png)

select * from t where b=12 and c=14 and d=3查找过程：

1. 存储引擎首先从根节点（一般常驻内存）开始查找，第一个索引列为1，b=12大于1小于56，于是读取中间指针指向下一个节点的磁盘文件地址，进行一次磁盘IO，将此节点加载到内存中
2. 然后根据第一步进行相同的判断，发现 数据都是匹配的，然后根据指针将此联合索引值所在的叶子节点也从磁盘中加载后内存，此时又发生了一次磁盘IO
3. 最终在叶子节点中查找到，叶子节点中索引值关联主键，根据主键进行回表(聚簇索引中去找)

![image-20220329105258179](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/image-20220329105258179.png)



##### 联合索引的最左前缀原则

创建的(b、c、d)索引相当于创建了 (b)、(b、c)、(b、c、d)三个索引，当b列值相等时，在以c列排序，c列的值相等时则以d列排序。联合索引只能从多列索引的第一列开始查找。如果查询条件不包含b(如:cd、c、d)则是无法应用缓存的以及跨列也是无法应用到索引的(例如：b，d)则只应用到了b



其中in和= 可以乱序：例如a=1 and c=2 and b=1  mysql优化器是会自动优化的，这个会走到索引



[索引覆盖与下推](https://www.jianshu.com/p/d0d3de6832b9)

#### 覆盖索引

> 执行计划中extra字段包含：Using Index

1. 只需要在索引树上就能获取SQL所需的所有列数据，无需回表，减少I/O操作，速度更快
2. 一个索引包含所有需要查询的字段值，则称为索引覆盖
2. explain的输出结果Extra字段为Using index时，表示触发使用了覆盖索引



#### 索引下推 ICP 优化

> 执行计划中Extra字段包含：Using Index Condition
>
> 是MySQL使用索引从表中检索行数据的一种优化方式，某些场景下能减少回表次数



MySQL5.6开始支持，5.6之前，存储引擎会通过遍历索引定位基表中的行，然后返回给Server层，Server层再去为这些数据行进行WHERE后的条件的过滤。MySQL5.6之后支持ICP，如果where条件中可以使用索引，MySQL会把这部分过滤操作放到存储引擎层，存储引擎通过索引过滤，把满足的行从表中读取出。ICP能减少引擎层访问基表的次数和Server层访问存储引擎的次数

Index Condition pushdown，执行计划中extra会出现：using index condition

在使用非主键索引进行索引查询时，首先根据索引来查找记录，然后在根据where条件来过滤记录。对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数。也就是说提前执行where的部分过滤操作，在某些场景下，可以大大减少回表次数，从而提升整体性能

select * from table where name like '张%' and age =10 ismale=1；

![image-20220316131642324](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220316131642324.png)

![image-20220316131658595](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220316131658595.png)

图 1 中，在 (name,age) 索引里面特意去掉了 age 的值，**这个过程 InnoDB 并不会去看 age 的值**，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。

图 2 跟图 1 的区别是，InnoDB 在 (name,age) **索引内部就判断了 age 是否等于 10**，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次



#### MySQL强制索引

强制索引，即指定本次查询使用某个特定的索引，这样就可以避免MySQL优化器使用低效的索引

~~~mysql 
select * from table 
force index (index_list)
where condition;
~~~



#### 索引设计原则?

索引的选择性：指**不重复的索引值和数据表中记录总数的比值**，索引的选择性越高则查询效率越高，因为索引选择性高的索引可以让MySQL在查找时过滤掉更多的行。主键索引和唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的

例如：下图中建立索引顺序的依据

![image-20220607143827485](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206071438951.png)

1. 经常被查询的列
2. 经常用于表连接的列
3. 经常排序
   - MySQL支持两种方式的排序
     - FileSort：效率低
     - Index：指MySQL扫描索引本身完成排序，效率高
   - Order By满足两种情况，会使用Index方式排序
     - Order By使用索引最左列，即满足最佳做前缀
     - 索引where与order by子句条件列组合满足索引最左前列
4. 经常分组的列
   - group by实质是先排序后分组，遵循最佳做前缀
   - where高于having，能写在where限定的条件就不要去having限定了

#### 索引失效情况

1. like以%开头的索引会失效，name like 'qqcc%'索引有效
2. 组合索引，应按照最左匹配原则，若使用的不是第一列索引时，则索引失效
   - 有些情况并没有，具体要通过Explain来分析分析
3. 索引列上使用 Is null，Is not null时，索引失效，因为索引不会索引空值
4. 索引字段上使用：not、<>、!=、不会走索引，而是全表扫描
5. 索引字段上计算、表达式运算、运用函数不会使用索引
6. or语句前后没有同时使用索引，即：or的前后两个字段都需要有索引，此时相当于底层进行的union操作





---

### 执行计划 Explain 

#### explain

> explain用来分析Select查询语句，通过分析Explain的结果来优化查询语句



MySQL中可以使用Explain、Describe获取MySQL执行Select语句的信息，来分析查询语句，不过通常使用Explain；Describe多用于查看表结构信息

~~~mysql
Explain Select 语句；
~~~

|      |                                |       |                                     |                  |                |         |      |                        |                |
| ---- | ------------------------------ | ----- | ----------------------------------- | ---------------- | -------------- | ------- | ---- | ---------------------- | -------------- |
| id   | select_type                    | table | type                                | possible_keys    | key            | key_len | ref  | rows                   | Extra          |
|      | 查询类型：简单、联合、子查询等 |       | 关联类型：Mysql决定如何查找表中的行 | 可能使用到的索引 | 实际使用的索引 |         |      | 估计要读取并检测的行数 | 额外的一些信息 |

1. id：select语句的编号，有几个select就有几个id，并且id的顺序是按照select出现的顺序增长的。如果在语句中没子查询或关联查询，只有唯一的 SELECT，每行都将显示 1。否则，内层的 SELECT 语句一般会顺序编号，对应于其在原始语句中的位置
2. select_type：表示对应行是简单还是复杂的查询
   - simple:简单查询
   - primary:复杂查询中最外层的select
   - subquery:包含在select中的子查询（不是在from子句中）
   - derived:包含在from子句中的子查询
   - union:在union中的第二个和随后的select
   - union result:从union临时表检索结果的select
3. table:当前行正在访问的表，当 from 子句中有子查询时，table列是 <derivenN> 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。当有 union 时，UNION RESULT 的 table 列的值为 <union1,2>，1和2表示参与 union 的 select 行id
4. type：表示关联类型或访问类型，即MySQL决定如何查找表中的行
   - 最优到最差为：
   - system:系统表，少量数据，往往不需要进行磁盘IO
   - const:常量连接，对查询的某部分进行优化并将其转化为一个常量
   - eq_ref：primary key或unique key索引等值扫描，最多只会返回一条符合条件的记录
   - ref：非主键、非唯一索引等值扫描
   - range：范围扫描。通常出现在in、between、>、<、>=等操作，使用一个索引来检索给定范围的行
   - index：索引树扫描。和ALL一样，不同就是mysql只需要扫描索引树，比All快一些
   - all：全表扫描
5. possible_keys：这一列显示查询可能使用哪些索引来查找
6. key：这一列显示mysql实际采用哪个索引来优化对该表的访问
7. key_len：这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列
8. ref：这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），NULL，字段名（例：film.id）
9. rows：这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数
10. Extra：额外信息
    - distinct： 一旦mysql找到了与行相联合匹配的行，就不再搜索了
    - Using index：这发生在对表的请求列都是同一索引的部分的时候，返回的列数据只使用了索引中的信息，而没有再去访问表中的行记录。是性能高的表现
    - Using where：mysql服务器将在存储引擎检索行后再进行过滤。就是先读取整行数据，再按 where 条件进行检查，符合就留下，不符合就丢弃
    - Using temporary：mysql需要**创建一张临时表来处理查询**。出现这种情况一般是要进行优化的，首先是想到用索引来优化
    - Using filesort：mysql 会**对结果使用一个外部排序**，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。

#### explain扩展

1. Explain extended：会在 explain  的基础上额外提供一些查询优化的信息。紧随其后通过 show warnings 命令可以 得到优化后的查询语句，从而看出优化器优化了什么。额外还有 filtered 列，是一个半分比的值，rows * filtered/100 可以估算出将要和 explain 中前一个表进行连接的行数（前一个表指 explain 中的id值比当前表id值小的表）

| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
| ---- | ----------- | ----- | ---- | ------------- | ---- | ------- | ---- | ---- | -------- | ----- |
|      |             |       |      |               |      |         |      |      |          |       |

2. Explain partitions：相比 explain 多了个 partitions 字段，如果查询是基于分区表的话，会显示查询将访问的分区



### MySQL-SQL优化工具

美团DBA团队开源工具：SQLAdvisor

它可以根据输入的SQL，输出索引优化建议



---

### MySQL日志

> 任何一种数据库中，都会有各种各样的日志，记录着数据库工作的各种操作。
>
> MySQL的日志是写前日志，即：先写日志、再写磁盘

https://mp.weixin.qq.com/s/PJCq5oQ3HSzWbA73bEUNuQ

MySQL中主要包括的日志：**二进制日志**、错误日志、查询日志、慢查询日志、**事务日志**(包括redo log、undo log )等等。其中比较重要的是二进制日志(binlog)、重做日志(redo log)、回滚日志(undo log)



#### Binarylog

> bin log是Server层的日志。
>
> 它是逻辑日志：可以简单理解为记录的是原始sql语句
>
> 物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更

https://zhuanlan.zhihu.com/p/227864607

Mysql会把所有表结构变更，以及表数据修改的操作 记录到一个二进制日志文件，也即BinaryLog文件，简称binlog。使用任何存储引擎的Mysql数据库都会记录binlog日志





binlog是通过追加的方式进行写入的，通过设置max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志

binlog日志是以事件的形式记录对MySQL的操作，还记录着各个操作消耗的时间

恢复事件4 - 事件1234之间的数据操作：

```mysql
$ mysqlbinlog --start-position=4 --stop-position=1234 /usr/local/var/mysql/binlog.000001 | mysql -uroot -p
```



##### binlog常用的场景

1. 数据恢复
   - 误删数据之后可以通过mysql binlog工具恢复数据
2. 主从复制
   - 主库开启binlog，然后将binlog传给从库(各个slave端)，从库接收到之后读取内容写入从库，实现主从数据一致
3. 审计
   - 通过二进制日志中的信息进行审计，判断是否对数据库进行注入攻击

binlog文件包含两种类型：

1. 索引文件(文件名后缀为.index)：用于记录哪些日志文件正在被使用
2. 日志文件(文件名为.00000*)：记录数据库所有的DDL和DML语句事件





##### binlog工作原理

binlog是MySQL用来记录数据库表结构变更以及表数据修改的二进制日志，它只会记录表的变更操作，但不会记录select和show这种查询操作



###### binlog刷盘时机

对于InnoDB存储引擎而言，只有在事务提交时才会记录biglog，此时记录还在内存中，那么biglog是什么时候刷到磁盘中的呢？mysql通过sync_binlog参数控制binlog的刷盘时机，取值范围是0-N：

- 0：不去强制要求，由系统自行判断何时写入磁盘；
- 1：每次commit的时候都要将binlog写入磁盘；
- N：每N个事务，才会将binlog写入磁盘

从上面可以看出，sync_binlog最安全的是设置是1，这也是MySQL 5.7.7之后版本的默认值



binlog如何记录数据库操作的？

###### binlog的3种记录模式

> 通过binlog_format=" xxx" 来修改日志模式



1. ROW：该格式记录的内容看不到详情信息，需要通过mysqlbinlog工具解析出来     5.7之后默认的记录模式
   - ![image-20220324095057636](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/image-20220324095057636.png)
2. STATEMENT：记录每一条修改数据的SQL语句（批量修改时，记录的不是单条SQL语句，而是批量修改的SQL语句事件）  5.7之前默认
3. MIXED：statement和row模式的混合



| 记录模式  | 优点                                     | 缺点                                                         |
| --------- | ---------------------------------------- | ------------------------------------------------------------ |
| ROW       | 能清楚记录每一个行数据的修改细节         | 批量操作，会产生大量的日志，尤其是alter table会让日志文件大小暴涨 |
| STATEMENT | 日志量小，减少磁盘IO，提升存储和恢复速度 | 在某些情况下会导致主从数据不一致，比如Sql语句中有last_insert_id()、now()等函数。 |
| MIXED     | 准确性强，文件大小适中                   | 当binlog format 设置为mixed时，普通复制不会有问题，但是级联复制在特殊情况下会binlog丢失。 |



###### Binlog文件结构

binlog文件记录的是对数据库的各种修改操作，用来记录修改操作的数据结构的Log event。不同的修改操作对应着不同的log event

常用的log event：Query event、Row event、Xid event等等

binlog文件的内容就是各种log event的集合

![image-20220323230705990](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203232307725.png)



###### Binlog写入机制

1. 根据设置的记录模式和操作生成相应的log event
2. 事务执行过程中产生log event会先写入缓冲区，每个事务线程都有一个缓冲区，Log Event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用于存放不支持事务的信息；另一个是trx_cache用于存放支持事务的信息
3. 事务在提交阶段会将产生的log event写入到外部binlog文件中。不同事务以串行方式将log event写入binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event



###### 配置binlog参数  

windows中 my.cnf文件，在mysqld节中修改配置信息

~~~mysql
[mysqld]
#设置记录模式
binlog_format = mixed

# 设置日志路径，注意路经需要mysql用户有权限写
log-bin = /data/mysql/logs/mysql-bin.log

# 设置binlog清理时间
expire_logs_days = 7

# binlog每个日志文件大小
max_binlog_size = 100m

# binlog缓存大小
binlog_cache_size = 4m

# 最大binlog缓存大小
max_binlog_cache_size = 512m
~~~







#### 重做日志(redo log)

> redo log是MySQL中innodb引擎级别，它是物理日志，记录的内容是：在某个数据页上做了什么修改
>
> 用来记录innodb存储引擎的事务操作的日志，不管事务是否提交都会记录下来，redo log 让MySQL拥有了崩溃恢复的能力

当数据库发生故障后，重启MySQL实例后，innoDB存储引擎会使用redo log恢复到发生故障前的时刻，以此来保证数据的完整性。

确保事务的持久性，防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性

`MySQL` 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 `Buffer Pool` 中。

后续的查询都是先从 `Buffer Pool` 中找，没有命中再去硬盘加载，减少硬盘 `IO` 开销，提升性能。

更新表数据的时候，也是如此，发现 `Buffer Pool` 里存在要更新的数据，就直接在 `Buffer Pool` 里更新。

然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（`redo log buffer`）里，接着刷盘到 `redo log` 文件里



##### 何时刷盘

1. 事务提交时：Innodb存储引擎为redo log的刷盘策略提供了一个参数：innodb_flush_log_at_tx_commit
   - 该值为0：表示每次事务提交时不进行刷盘操作
   - 设置为1：表示每次事务提交时都将进行刷盘操作（默认值）
   - 设置为2：表示每次事务提交时都只把 redo log buffer 内容写入 page cache
2. log buffer空间不足时
   - log buffer 的大小是有限的，如果不停的往这个有限大小的log buffer里写入日志，很快就会被填满，**如果当前写入log buffer的redo日志量已经占满了log buffer总容量的大约一半左右，就需要把这些日志刷新到磁盘上**
3. 后台线程不停的刷盘
   - 默认后台有一个线程，大约每秒刷新一次log buffer中的redo log到磁盘
4. 正常关闭服务时



##### redo log日志文件组

硬盘上存储的redo log日志文件不止一个，而是以一个日志文件组的形式存在的，每个redo log日志文件大小都是一样的





#### binlog和redo log区别

1. binlog属于MySQL server层面，redo log属于Innodb层面，这样数据库用别的存储引擎时就可以达到一致性的要求
2. binlog是逻辑日志，记录的是sql语句的原始逻辑；redo log是物理日志，记录该数据页更新的内容
3. binglog是追加写，一份文件写到一定大小的时候就会换下一个文件写入，不会覆盖；redo log是循环下，日志空间大小固定
4. binlog可以作为恢复数据使用，主从复制搭建；redo log作为异常宕机、介质故障后的恢复数据使用



#### 回滚日志(undo log)

> 在MySQL中，回滚机制是通过undo log机制实现的，所有事务进行的修改都会记录到这个回滚日志中，然后再执行相关的操作
>
> 使用undo log来保证事务的原子性



undo：撤销、使恢复原则、撤销还原

除了记录redo log之外，当进行数据修改时，还会记录 undo log，undo log用于数据的撤回操作，他保留了记录修改前的内容。

回滚日志先于数据持久化到磁盘上，这就保证了即使遇到数据库突然宕机的情况，再次启动数据库时，可以通过查询回滚日志来回滚之前为完成的事务

另外，MVCC多版本并发控制，依赖于undo log实现









#### 错误日志

记录mysqld启动和停止时、服务器运行过程中发生任何严重错误的相关信息。

错误日志是默认开启的，默认存放目录var/lib/mysql  默认文件名为 主机.err

![image-20220323233829559](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203232338770.png)



#### 查询日志

查询日志中记录了客户端所有操作语句，但是二进制日志不包含查询数据的日志

默认情况下，查询日志是未开启的。可以设置开启：

~~~mysql
#该选项用来开启查询日志 ， 可选值 ： 0 或者 1 ； 0 代表关闭， 1 代表开启 
general_log=1

#设置日志的文件名 ， 如果没有指定， 默认的文件名为 host_name.log 
general_log_file=file_name
~~~



#### 慢查询日志

慢查询日志记录了所有执行事件超过参数long_query_time设置值并且扫描记录数不小于min_examined_row_limit的所有的sql语句的日志

long_query_time默认为10s，最小为0，精度可以到微妙

慢查询日志默认是关闭的。通过设置来控制慢查询日志：

~~~sql
# 该参数用来控制慢查询日志是否开启， 可取值： 1 和 0 ， 1 代表开启， 0 代表关闭
slow_query_log=1 

# 该参数用来指定慢查询日志的文件名
slow_query_log_file=slow_query.log

# 该选项用来配置查询的时间限制， 超过这个时间将认为值慢查询， 将需要进行日志记录， 默认10s
long_query_time=10
~~~

![image-20220323234539004](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203232345184.png)

https://blog.csdn.net/m_awdawdw/article/details/107665827

---



### MySQL主从同步/复制

> 主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器(master)，其余的服务器充当从服务器(slave)



#### MySQL主从复制原理

> 主要涉及三个线程：binlog线程、I/O线程、SQL线程

binlog  dump线程：主库创建一个binlog dump线程，负责发生binlog日志文件，从库的I/O线程负责接收

I/O线程：负责从主服务器上读取binlog日志文件，并写入到从服务器的中继日志中

SQL线程：负责读取中继日志，并重放其中的SQL语句(再执行一遍sql语句)



主服务器有一个工作线程I/O dump thread，从服务器有两个工作线程，一个是I/O threa、一个是SQL thread

1. 主库master将外界接收的SQL请求记录到自己的binlog文件中，从库I/O thread去请求主库的binlog日志，并将得到的binlog日志写入到自己的Relay log（中继日志)文件中。然后在从库上重做应用中继日志中的SQL语句。主库通过I/O dump thread给从库I/O thread传送binlog日志
2. ![image-20220604212100309](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206042121964.png)

MySQL主从复制，默认采用**异步复制方式进行的**，所以从服务器不需要一直连着主服务器，从服务器甚至可以通过拨号断断续续的连接主服务器。通过配置文件，可以指定复制所有的数据库、某个数据库甚至是数据库上的某个表

异步复制不足之处：当主库把事件写入binlog后，并不知道从库是否接收并应用了。若主库宕机，可能主库中已经提交事务，但是并没有传到任何一台从库机器上，高可用集群架构下，切换主从，就会造成新的主库丢失数据的现象



##### 为什么要做主从同步

1. 读写分离，使数据库支撑更大的并发
2. 在主服务器上生成实时数据，从服务器上分析这些数据，从而提高主服务器的性能
3. 数据备份，保证数据的安全



#### MySQL 主从-读写分离

> 主服务器处理写操作以及实时性要求比较高的读操作。从服务器处理读操作



读写分离如何提高性能？

1. 主服务器负责各自的读和写，极大程度缓解了锁的争用
2. 增加冗余，提高可用性



##### 如何实现读写分离

读写分离常常采用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。

提供类似的代理中间件有：MyCat、Sharding-JDBC等等

![image-20230404152351685](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202304041523226.png)

#### 读写分离带来的问题

> 主库和从库之间数据存在延迟，这是很多主-从架构的问题，并不是MySQL才存在

如何解决？

1. **强制将读请求路由到主库处理**

   - 既然从库数据过期了，那就直接读取主库。问题就是会给主库增加压力，当时实现比较简单
   - Sharding-JDBC就是采用这种方案，根据它的分片键值管理器，可以强制使用主库
   - 对于这种方案：必须获取最新数据的读请求都交给主库处理

2. **延迟读取**

   - 比如主从同步延迟了1s，那我1.5s之后再去读取数据
   - 需要看具体的业务场景

   



---



### MySQL锁机制

数据库锁机制简单来说主要是为了保证数据的一致性，使各种共享资源在被并发访问时变得有序而设计的一种规则。MySQL不同存储引擎支持不同的锁机制

### InnoDB的锁类型

InnoDB的**行锁类型**主要有：读、写、MDL锁

InnoDB表锁：意向锁

1. 行锁-读锁：简称S锁，一个事务获取了一个数据行的读锁，其他事务能获得该行对应的读锁，但不能获得写锁，即一个事务在读取一个数据行时，其他事务也可以读，但不能对该数据行进行增删改的操作
2. 行锁-写锁：简称X锁，一个事务获取了一个数据行的写锁，其他事务就不能再获取该行的其他锁，写锁优先级最高。一些DML语句的操作都会对行记录加写锁。比较特殊的就是select for update，它会对读取的行记录上加一个写锁，那么其他任何事务就不能对被锁定的行上加任何锁了，要不然会被阻塞
3. 行锁-MDL锁：meta data lock简称MDL锁，用于保证表中元数据的信息。例如会话A开启事务后，会自动获得一个MDL锁，会话B不能进行任何DDL操作。例如此时B不能往表中添加字段的操作等等
4. 意向锁：是表级锁，分为意向共享锁IS和意向排他锁IX
   - IS：是指在给一个数据行加共享锁前必须先取得该表的IS锁
   - IX：是指在给一个数据行加排他锁前必须先取得该表的IX锁
   - 意向锁作用与MDL锁类似，都是防止事务进行中，执行DDL语句的操作导致数据的不一致



#### 按照锁粒度分类

锁粒度从大到小：表锁、页锁、行锁；以及特殊场景下使用的全局锁

##### 表锁

表级别的锁是MySQL各种存储引擎中最大颗粒度的锁机制。该锁机制最大的特定是实现逻辑简单、带来的系统负面影响最小。索引获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所有可以很好的避免死锁问题

缺点：锁定资源争用的概率最高，大大降低了并发度

使用表级锁的主要是MyISAM、Memory、Csv等一些非事务型存储引擎，当然Innodb也是支持，不过默认并不是表锁定

##### 页锁

页锁的锁定颗粒的介于表锁和行锁之间，能提供的并发处理能力页锁介于二者之间。会发生死锁问题

使用页锁的主要是BerkeleyDB存储引擎

##### 行锁

特点：开销大，加锁慢；会出现死锁；锁粒度小，锁冲突概率低，并发读相对表锁较高

行级锁分为：共享锁和排他锁

锁定对象的颗粒的最小，所有发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力

缺点：由于资源锁定颗粒的最小，所有每次获取锁和释放锁需要做的事情更多，带来的消耗也就更大，此外行级锁最容易发生死锁

InnoDB存储引擎主要使用行锁

适用场景：表级锁更适合查询为主，只有少量按索引条件更新数据的应用；行级锁更适合有大量按索引条件并发风险数据的情况，同时又有并发查询的应用场景

##### 全局锁

全局锁，是对整个数据库实例加锁。使用场景：一般为全库逻辑备份



#### 按照锁级别分类

共享锁、排他锁、意向锁

如果事务 T1 持有r行 的 s 锁(行-读锁)，那么另一个事务 T2 请求 r 的锁时，会做如下处理：

- T2 请求 s 锁立即被允许，结果 T1 T2 都持有 r 行的 s 锁
- T2 请求 x 锁不能被立即允许

如果 T1 持有行的 x 锁，那么 T2 请求行的 x、s 锁都不能被立即允许，T2 必须等待T1释放 x 锁才可以，因为X锁与任何的锁都不兼容

##### 共享(读)锁

共享锁，也叫读锁，是读取操作(select)时创建的锁。其他用户可以并发读取数据，但是在读锁未释放前，也就是查询事务结束前，任何事务都不能对数据进行修改(获取数据上的写锁)，直到已释放所有读锁

~~~sql
#sql显示加锁写法：

select xxxxx      Lock in share mode;

# lock in share mode:查询语句后面添加了该语句，mysql会对查询结果中的每一行都加读锁
~~~



##### 排他(写)锁

排他锁，又叫写锁、独占锁，当A事务对数据data加上写锁后，其他事务不能再对数据data加任何类型的锁，获取写锁的事务既能读取数据，又能修改数据

~~~sql
select...  for update;
~~~

##### 意向锁 (Intention Lock)

意向锁属于表级锁，其设计目的主要目的是为了表明某个事务正在锁定一行或将要锁定一行

1. 意向共享锁(IS)：表示事务准备给数据行加共享锁，也就是说一个数据行加共享锁前必须先取得该表的意向共享锁
2. 意向排他锁(IX)：表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的意向排他锁

意向锁是InnoDB自动加的，无需用户干预

对应Insert、update、delete，Innodb会自动给设计的数据加排他锁；对于一般的select语句，Innodb不会加任何锁，事务可以通过以下语句显示加共享锁或排他锁

~~~sql
共享锁：SELECT … LOCK IN SHARE MODE;
排他锁：SELECT … FOR UPDATE;
~~~



https://blog.csdn.net/cy973071263/article/details/105188519?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&utm_relevant_index=10



#### InnoDb引擎为解决幻读等并发场景下事务存在的数据问题，引入的锁



##### 行记录锁(Record Locks)

单个行记录上的锁，也就是日常认为的行锁。主键和唯一索引都是行记录的锁模式，**InnoDB的行锁是加在索引上的**

~~~sql
update user set age=18 where name='qianchao';
#因为name不是索引，所以此时会把所以记录都上写锁，即：锁表
update user set age=18 where name='yyy';  #上一个事务未提交前，会出现锁超时
~~~



##### 间隙锁(Gap Locks)

即InnoDB默认的事务隔离级别RR已经解决幻读，就是临键锁（行锁+间隙锁）的功劳

锁定一个行记录的范围，但不包括记录本身（只不过它的锁粒度比记录锁的锁整行更大一些，他是锁住了某个范围内的多个行，包括根本不存在的数据）。Gap锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。该锁只会在隔离级别是RR或者以上的级别内存在。间隙锁的目的是为了让其他事务无法在间隙中新增数据，即不允许在此范围内插入任务数据

在RC读已提交隔离级别下，间隙锁不起作用

**产生条件**

1. 使用普通索引锁定
2. 使用多列唯一索引
3. 使用主键索引锁定多行记录

**打开间隙锁设置**

~~~sql
show variables like 'innodb_locks_unsafe_for_binlog';
默认：OFF ,即启用间隙锁
~~~



##### 临键锁(next-key Lock)  行锁+间隙锁组合

左开右闭区间

普通索引默认就是临键锁模式

它是记录锁和间隙锁的结合，该记录和它前面的区间都被锁定。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。next-key锁是InnoDB默认的锁

当InnoDB扫描索引记录时，会先对选中的索引记录加上记录锁（Record Lock），再对索引记录两边的间隙上加上间隙锁

假设有记录id=1, 3, 5, 7，现在记录5上加next-key lock，则会锁定区间(3, 5]，任何试图插入到这个区间的记录都会阻塞。

 

注意，由于其效果相当于(3, 5)上的gap lock加5上的record lock，而且gap lock是可重入的，相互不阻塞的(上文讲过)，当其它事务试图获取(3, 5)的gap lock时，不会被阻塞；但如果要获取5上的record lock，就会阻塞；如果要获取5上的next-key lock，同样会阻塞

这三种锁都是排他锁

这三种锁都是加在索引上的。假设有1，3，5，7，则5上的记录锁会锁住5，gap lock会锁住（3，5），next-key lock会锁住（3，5]

next-key lock 锁的是索引，而不是数据本身，所以如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁



#### 面向编程的两种锁思想

乐观锁和悲观锁并不是Mysql或数据库独有的概念，是两种并发控制的思想

主要区别在于：操作共享数据时，“悲观锁”即认为数据出现冲突的可能性更大，而“乐观锁”则是认为大部分情况不会出现冲突，进而决定是否采取排他性措施。

反映到 MySQL 数据库应用开发中，悲观锁一般就是利用类似 SELECT … FOR UPDATE 这样的语句，对数据加锁，避免其他事务意外修改数据。乐观锁则与 Java 并发包中的 AtomicFieldUpdater 类似，也是利用 CAS 机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。

MySQL的多版本并发控制 （MVCC），其本质就可以看作是种乐观锁机制，而排他性的读写锁、两阶段锁等则是悲观锁的实现


##### 悲观锁

假定并发冲突，在查询完数据的时候就把事务锁起来，直到提交事务。

实现方式：使用数据库中锁机制

##### 乐观锁

假设不会发生并发冲突，只在提交操作的时候检查数据是否被修改过。

给表增加version字段，在修改提交之前检查version与原来的version值是否相等。若相等，表示数据没有被修改，可以更新；否则数据为脏数据不能更新。

实现方式：乐观锁一般使用版本号机制或CAS算法实现



#### 自增锁 (auto-inc锁)

自增锁是一种特殊的**表级锁**，主要用于事务中插入自增字段，也就是我们最常用的自增主键id。通过innodb_autoinc_lock_mode参数可以设置自增主键的生成策略。防止并发插入数据的时候自增id出现异常。

当一张表的某个字段是自增列时，innodb会在该索引的末位加一个排它锁。为了访问这个自增的数值，需要加一个表级锁，不过这个表级锁的持续时间只有当前sql，而不是整个事务，即当前sql执行完，该表级锁就释放了。其他session无法在这个表级锁持有时插入任何记录



---



#### 锁等待和死锁

锁等待：是指一个事务过程中产生的锁，其他事务需要等待上一个事务释放它的锁，才能占用该资源。如果该事务一直不释放，就需要持续等待下去，直到超过了锁等待时间，会报一个等待超时的错误

死锁：mysql中，当两个及以上的事务，双方都在等待对方的锁资源，或者因为加锁顺序不一致造成**互相等待锁资源**，就会出现死锁

例如：事务A持有x1锁，申请x2锁；事务B持有x2锁，申请x1锁。此时A和B事务持有锁并且申请对方持有的锁，进入循环等待造成死锁

Mysql出现死锁的几个要素：

1. 两个或以上的事务
2. 每个事务都已经持有锁，并且申请新的锁
3. 锁资源同时只能被同一个事务持有
4. 事务之间因为持有锁和申请锁导致了循环等待

InnoDB可以自动检测死锁，并自动回滚该事务

~~~sql
show engine innodb status;#可查看死锁信息
~~~



##### MySql死锁检测机制

死锁机制包含两部分：检测和处理



##### 如何避免死锁

1. 设置事务等待锁的超时时间

   - 当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 `innodb_lock_wait_timeout` 是用来设置超时时间的，默认值时 50 秒

2. 开启主动死锁检测

   - 主动死锁检测在发现死锁后，主动回滚死锁链中的某一个事务，让其他事务得以继续执行

   - ~~~sql
     innodb_deadlock_detect 设置为on,表示开启这个逻辑，默认为开启状态
     ~~~

   

##### 锁问题的监控

~~~sql
show full processlist;
show engine innodb status;
~~~

比较重要的三张表：Innodb_TRX、Innodb_Locks、Innodb_Lock_Waits



----



### truncate、delete、drop

1. truncate和delete只删数据，不删除表的结构，但是truncate在事务中不能被回滚并且会清空表的自增属性下一次从1开始记录，而delete不会删除自增属性
1. truncate：删除内容、释放空间、但是不删除定义(表结构还在)，不能删除部分数据行，只能全表删除
1. delete：删除内容、不释放空间、不删除表定义，可以部分删除
2. drop将删除表的数据、结构、被依赖的约束、触发器、索引，释放空间



一般来说，执行速度：drop>truncate>delete



### MySQL常见控制流函数

case when  ....   then ....else ....  end ：适用于增删改查各类语句

~~~sql
update user_info u
set  u.balance= 

case 
when u.set='女' and u.age>18 
then u.balance+10
else u.balance+5
end

where u.create_time>='2020-01-01';

~~~

---



### MySQL分页

#### 什么是分页

一般在客户端实现分页功能的时候，要显示当前页的数据、当前所在页数、临近页面的按钮以及总页数等等。这些数据随着翻页的进行能够动态的变化，为了实现这样的效果，一般会采取两种办法：**真分页**和**假分页**

#### 真分页(物理分页)

真分页指的是每次在进行翻页时都只查询出当前页面的数据，特点就是与数据库的交互次数较多，但是每次查询的数据量较少，数据也不需要一直保存在内存中。适用于数据量比较大的场景，数据不适合全量查出的情况

#### 假分页(逻辑、内存分页)

假分页指的是对于要显示的数据一次性全部查出，一直存在在服务端或客户端，在前端进行分页或由服务端控制分页。将根据当前所在页来计算应该显示的数据所在下标，用循环取出目标数据。只有当会话断开或页面关闭，相应的资源才会被释放

#### MySQL实现分页

mysql使用limit来限制查询出来的数据，属于真分页

~~~sql
#查询前5条
select * from student limit 5;
#查询第一到第十条
select * from student limit 0,10;
#查询第11-第20条
select * from student limit 10,10;

#指定两个参数时，第一个代表偏移量，第二个代表取出的数据条数
#offset可省略
select * from student limit 10,10;
select * from student limit 10 offset 10
# select * from student limit ( offset pageSize)
~~~

##### 分页公式

1. 进行分页前，计算出总量来得出总页数

   ~~~sql
   select count(*) from student;
   #假如每页显示10条，直接进行除法，然后向上取整。得到总页数
   select ceil(count(*)/10) as pageTotal from student;
   ~~~

2. 核心信息

   - 当前页：pageNumber
   - 每页数据量：pageSize

3. 公式

   - offset ：（pageNumber-1)*pageSize
   - rows：pageSize



---



### 大表优化

MySQL方案，根据数据库的特性来优化，每种数据库优化方式各不同

#### 单表优化

1. 涉及表结构时
   - 避免字段null值，null查询优化很难且占用额外的索引空间，推荐加上默认值
   - 字段的设计
   - 索引、索引相关东西
   - sql优化

---



### processlist

显示用户正在运行的线程



---



### 查询执行过程

客户端发起查询请求后：首先连接mysql，然后发布查询，如果缓存中(内存)有结果集则直接返回结果集。如果缓存中没有，那么mysql解析查询，通过优化器生成执行计划，然后运行执行计划，通过API从存储引擎获取数据并返回给客户端



---

### MySQL一条SQL的执行过程详解

#### MySQL驱动

1. 系统和MySQL数据库进行交互前，MySQL驱动会帮我们建立连接。一次SQL请求就会建立一个连接，多个请求就会建立多个连接。由于性能原因，引入数据库连接池

2. ![image-20220315211512773](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152115509.png)

    

3. 数据库连接池

   - 维护一定的连接数，方便系统获取连接，使用时从池子中获取，用完之后放回去就可以了。我们不用关系连接的创建和销毁，因为不必关心线程池是怎么去维护这些连接的
   - 常见的数据库连接池Druid、C3P0、DBCP
   - 好处：大大节省了不断创建和销毁连接而带来的性能开销
   - ![image-20220315211611686](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152116696.png)

   

#### 数据库连接池

1. MySQL架构提供了数据库连接池，双方都是通过数据库连接池来管理各个连接的，这样一方面线程之前不需要是争抢连接，更重要的是不需要反复的创建的销毁连接
2. ![image-20220315211635997](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152116888.png)

#### 网络连接必须由线程来处理

1. 所谓网络连接，说白了就是一次请求，每次请求都会有相应的线程去处理。对于 SQL 语句的请求在 MySQL 中是由一个个的线程去处理的
2. ![image-20220315211657924](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152117993.png)

#### SQL接口

MySQL中处理请求的线程在获取到请求以后，获取的SQL语句交给SQL接口去处理

#### 查询解析器

~~~sql
--例如：以下SQL
select studentName from students where id=1;
~~~

1. 解析器将SQL接口传递过来的SQL语句进行解析，翻译成MySQL数据库自己能认识的语言
2. ![image-20220315211758377](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152117498.png)
3. 现在请求的SQL语句已经解析为MySQL数据库能认识的样子了，下一步MySQL会按照自己任务效率最高的方式去执行SQL语句

#### MySQL查询优化器

1. MySQL会为我们生成一条条的执行计划。比如你创建了多个索引等等
2. 优化器选出最优索引等步骤后，由执行器去调用存储引擎接口，开始去执行被MySQL解析过和优化过的SQL语句
3. ![image-20220315211814567](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152118692.png)

#### 执行器

1. 执行器是一个非常重要的组件，因为前面那些组件的操作最终必须通过执行器去调用存储引擎接口才能被执行。执行器最终会根据一系列的执行计划去调用存储引擎的接口去完成 SQL 的执行
2. ![image-20220315211830067](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152118217.png)

#### 存储引擎

查询优化器会调用存储引擎的接口，去执行 SQL，也就是说真正执行 SQL 的动作是在存储引擎中完成的。数据是被存放在内存或者是磁盘中的（存储引擎是一个非常重要的组件，后面会详细介绍

#### 初识存储引擎

~~~mysql
#以更新sql举例
update students set studentName='小强' where id=1；
~~~

1. 当Java系统发出这样的查询交给MySQL时，它会按照上面的一系列流程最终通过执行器调用存储引擎去执行
2. 执行这个sql时候，sql对应的数据要么在内存中、要么在磁盘上，如果直接在磁盘中操作，那么随机IO的读写速度肯定是很慢的，所以每次执行SQL的时候，都会将数据加载到内存中，这块内存就是InnoDB中一个非常重要的组件：缓存池（Buffer Pool）

##### Buffer Pool

1. 顾名思义，缓冲池其实就是类似  Redis  一样的作用，起到一个缓存的作用，因为我们都知道 MySQL 的数据最终是存储在磁盘中的，如果没有这个 Buffer Pool  那么我们每次的数据库请求都会磁盘中查找，这样必然会存在 IO 操作，这肯定是无法接受的
2. 有了 Buffer Pool 就是我们第一次在查询的时候会将查询的结果存到  Buffer Pool 中，这样后面再有请求的时候就会先从缓冲池中去查询，如果没有再去磁盘中查找，然后在放到  Buffer Pool 中，如下：
3. ![image-20220315211848501](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152118602.png)
4. 此条SQL执行步骤大致如下：
   - innodb 存储引擎会在缓冲池中查找 id=1 的这条数据是否存在
   - 发现不存在，那么就会去磁盘中加载，并将其存放在缓冲池中
   - 该条记录会被加上一个独占锁（总不能你在修改的时候别人也在修改吧，这个机制本篇文章不重点介绍，以后会专门写文章来详细讲解）

##### undo日志文件：记录数据被修改前的样子

undo log 就是没有发生事情的一些日志

1. 在将SQL查询到的数据加载到Buffer Pool时，同时会往undo日志文件插入一条日志，也就是将id=1这条记录的原来的值记录下来
2. 这样做的目的？
3. Innodb 存储引擎的最大特点就是支持事务，如果本次更新失败，也就是事务提交失败，那么该事务中的所有的操作都必须回滚到执行前的样子，也就是说当事务失败的时候，也不会对原始数据有影响
4. ![image-20220315211906526](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152119619.png)
5. 到这一步，我们的执行的 SQL 语句已经被加载到 Buffer Pool 中了，然后开始更新这条语句，更新的操作实际是在Buffer Pool中执行的，此时就会造成Buffer Pool和数据库中的数据不一致问题

##### redo日志文件：记录数据被修改后的样子

1. 除了从磁盘中加载文件和将操作前的记录保存到 undo 日志文件中，其他的操作是在内存中完成的，内存中的数据的特点就是：断电丢失。如果此时 MySQL 所在的服务器宕机了，那么 Buffer Pool 中的数据会全部丢失的。这个时候 redo 日志文件就需要来大显神通了
2. redo日志文件是InnoDB特有的，它是存储引擎级别的，不是MySQL级别的
3. redo 记录的是数据修改之后的值，不管事务是否提交都会记录下来。例如，此时将要做的是update students set stuName='小强' where id=1; 那么这条操作就会被记录到 redo log buffer 中，啥？怎么又出来一个 redo log buffer ,很简单，MySQL 为了提高效率，所以将这些操作都先放在内存中去完成，然后会在某个时机将其持久化到磁盘中。
4. ![image-20220315211924682](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152119795.png)
5. MySQL执行器调用存储引擎是怎么将SQL加载到缓冲池和记录哪些日志文件的流程如下：
   - 准备更新一条SQL语句
   - MySQL(InnoDB)会先去缓冲池中查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（BufferPool）中
   - 在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中
   - innodb 会在 Buffer Pool 中执行更新操作
   - 更新后的数据会记录在 redo log buffer 中
6. 此时SQL语句已经更新完成，需要将更新的值提交，也就是需要提交本次的事务了。因为只要事务成功提交了，才会将最后的变更保存到数据库中，在提交事务前仍然会进行相关的操作
7. 将  redo Log Buffer 中的数据持久化到磁盘中。就是将 redo log buffer 中的数据写入到 redo log 磁盘文件中，一般情况下，redo log Buffer 数据写入磁盘的策略是立即刷入磁盘，如下：
8. ![image-20220315211938384](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152119526.png)
9. 到此为止，**从执行器开始调用存储引擎接口做了哪些事情呢**？
   - 准备更新一条 SQL 语句
   - MySQL（innodb）会先去缓冲池（BufferPool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（BufferPool）中
   - 在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中
   - innodb 会在 Buffer Pool 中执行更新操作
   - 更新后的数据会记录在 redo log buffer 中
   - MySQL 提交事务的时候，会将 redo log buffer 中的数据写入到 redo 日志文件中。刷磁盘可以通过 innodb_flush_log_at_trx_commit 参数来设置 
     - 值为 0 表示不刷入磁盘
     - 值为 1 表示立即刷入磁盘
     - 值为 2 表示先刷到 os cache
   - myslq 重启的时候会将 redo 日志恢复到缓冲池中

##### bin log：记录整个操作过程

1. redo log记录的东西是偏向于物理性质的，如：“对什么数据，做了什么修改”。 InnoDB 存储引擎特有的日志文件
2. bin log是偏向于逻辑性质的，类似于：“对 students 表中的 id 为 1 的记录做了更新操作”。是 MySQL 级别的日志
3. 两者的特点总结：

| 性  质   | REdo log                                                     | bin log                                                      |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 文件大小 | redo log 的大小是固定的（配置中也可以设置，一般默认的就足够了） | bin log 可通过配置参数max_bin log_size设置每个bin log文件的大小（但是一般不建议修改）。 |
| 实现方式 | 是InnoDB引擎层实现的                                         | 是 MySQL 层实现的，所有引擎都可以使用 bin log日志            |
| 记录方式 | 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志     | 通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 |
| 使用场景 | 适用于崩溃恢复(crash-safe)（这一点其实非常类似与 Redis 的持久化特征） | 适用于主从复制和数据恢复                                     |

##### bin log文件是如何刷入磁盘的

bin log在什么时候记录数据？

1. MySQL 在提交事务的时候，不仅仅会将 redo log buffer  中的数据写入到redo log 文件中，同时也会将本次修改的数据记录到 bin log文件中，同时会将本次修改的bin log文件名和修改的内容在bin log中的位置记录到redo log中，最后还会在redo log最后写入 commit 标记，这样就表示本次事务被成功的提交了
2. ![image-20220315212002795](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152120930.png)

MySQL有一个后台线程，它会在某个时刻将Buffer Pool中的脏数据刷到MySQL数据库中，这样内存和数据库的数据就保持一致了

![image-20220315212012776](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/img/202203152120920.png)





---

### 面试题目

https://blog.csdn.net/dl674756321/article/details/102987984

#### 一颗高度为3的B+Tree可以存放多少数据

B+Tree聚簇索引索引**节点**的单位是数据页，MySQL中B+树的一个节点大小为1页，即默认16k

假如Mysql一行数据大小为1k

问题针对：存储引擎为Innodb的主键索引才会出现这个问题，因为Innodb数据文件和索引文件(主键、聚簇索引)是放在一起的

1. Mysql页默认大小为16k
2. b+tree为叶子节点存放完整的数据，假设一条数据大小为1K，则叶子节点一页可以存放16条数据，B+树的叶节点就是数据页
3. 非叶子节点存放主键和指针，所以要看主键是什么类型的，假如为Integer，则长度为8字节，指针大小在innodb是6个字节，所以非叶子节点每页可以存16384/14=1170个主键数据和指针，则三层B+Tree可以存1170 * 1170 *16=21902400条数据(2000w+)



#### SQL查询语句执行先后顺序

~~~mysql
select * from student where age='zhangsan' group by age having age>10 order by age
~~~

1. from
   - 执行笛卡尔积(若是表关联)，对from子句的笛卡尔积生成一个虚拟表VT1
2. on
   - 对虚拟表VT1应用过滤器，生成VT2虚拟表
3. Join
   - 若指定了join
4. where
   - 由于数据还没有分组，所以不能再where中使用聚合函数来对分组统计的过滤
   - 由于没有进行列选择，因此，此时在select中使用的列是不被允许的
5. group by：将过滤出来的数据进行分组
6. having：对已经分组的数据进行过滤条件
7. select：需要的字段，产生虚拟表VT(x)
8. distinct去重
   - 从select产生的虚拟表中去重
9. order by：对结果集进行排序
10. limit/offset：返回指定数量行





#### MySQL锁与索引的关系

1. InnoDB行锁的实现：是通过给索引上的索引项加锁来实现的
   - 即使建表的时候没有指定主键，InnoDB会创建一个默认的DB-row_id的自增字段为表的主键，并且其主键索引为Gen_clust_index
2. InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才会使用行锁，否则InnoDB将使用表锁**
3. 一般情况下，mysql是不会隐式的去调用全局锁和表锁，除非不走索引去更新的情况，这也是为什么我们提倡做update&delete操作的时候，必须以主键为条件，一是为了使用行锁，二是为了避免复杂的where条件，以免造成数据更新或删除错误

Oracle中是通过在数据项中对相应数据行加锁来实现的





#### MySQL死锁检测

解锁顺序，先解锁哪个事务，为什么，死锁检测算法

##### 如何尽可能避免死锁

1. **大事务拆小**
2. 同一个事务中，尽可能做到一次锁定所需的所有资源，减少死锁概率
3. 为表添加合理的索引，原因就是mysql的行锁是建立在索引上的

##### 死锁解决办法

1. 设置超时时间
   - 两个事务出现死锁后，其中一个事务先到达设定的阈值后，该事务进行回滚，另一个事务可以继续执行
   - 弊端：若超时事务的操作很多，则使用undo log进行回滚时的消耗可能比未超时的事务要大的多
2. wait-for graph
   - 此死锁检测算法是InnoDB使用的死锁解决办法
   - wait-for graph保存有两种信息
     - 锁的信息链表
     - 事务等待链表
   - 通过上述锁链表、事务链表构造一张图，若图中存在回路则说明存在死锁
     - 事务T1->T2的边定义为：T1等待T2锁占用的资源，T1发生在T2的后面
     - ![image-20220607222032793](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/mysql_img/202206072221160.png)
   - 若有死锁，InnoDB会选择回滚undo  log量最小的事务





#### MySQL可以直接存储文件吗(比如：图片)

1. 可以是可以，直接存储文件对应的二进制数据就好。不过，不建议在数据库中存储文件，会严重影响数据库性能，消耗过多存储空间
   - 可以选择云服务厂商提供的文件存储服务，成熟稳定，价格比较低
2. 可以选择自建文件存储服务
   - 可以基于FastDFS、MinIO等开源项目实现分布式文件服务
   - 公司采用的是分布式文件存储系统HDFS



#### MySQL如何存储Ip地址

不建议采用字符串方式存储

可以将Ip地址转化为32位的整形数字存储

同时mysql提供了Inet_aton()：将ip转换为无符号整型（4-8位），Inet_ntoa()：把整型的ip转换为地址
