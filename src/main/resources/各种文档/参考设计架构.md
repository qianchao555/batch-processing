



## 架构

### 异常处理、国际化

继承RuntimeException，提供对XXXBaseException可以整合message国际化

国际化：resources目录下，i18n目录下，文件格式为messages_语言类型.properties、_

存在多模块时候：文件格式为messages_[模块名]__语言类型.properties

---



### 验证（Validation）

#### jakarta.validation自带验证

1. 声明字段约束

   ~~~java
   // 非空
   //message为验证失败提示信息，结合i18n实现国际化
   @NotBlank(message = "{name.empty.error}")
   private String name;
    
   // 长度限制
   @Size(min = 6)
   private String pass;
    
   // 当前时间以前
   @Past
   private Date pastDate;
    
   // 当前时间以后
   @Future
   private Date futureDate;
    
   // 正则校验
   @Pattern(regexp = "^[0-9]+")
   private String patterStr;
    
   // 范围
   @Range(min = 0, max = 100)
   private Integer num;
   ~~~

   

2. 开启参数验证：在接口传入参数前添加@Valid

~~~java
@PostMapping("test")
public ValidTestEntity test(@RequestBody @Valid ValidTestEntity entity) {
    return entity;
}
~~~



#### 自定义验证 (校验)注解

1. 定义注解类

   ~~~java
   @Target({ FIELD })
   @Retention(RUNTIME)
   //指定验证器
   @Constraint(validatedBy = MyValidator.class)
   public @interface MyChecker {
       String message() default "{myChecker.error}";
    
       // 分组
       Class<?>[] groups() default {};
    
       // 负载
       Class<? extends Payload>[] payload() default {};
   }
   ~~~

   

2. 实现验证逻辑

   ~~~java
   //第一个泛型为注解类型，第二个泛型为验证的字段类型
   public class MyValidator implements ConstraintValidator<MyChecker, String> {
       @Override
       public void initialize(MyChecker constraintAnnotation) {
           //通过注解实例获取注解信息
           System.out.println(constraintAnnotation.message());
       }
    
       @Override
       public boolean isValid(String s, ConstraintValidatorContext constraintValidatorContext) {
           //验证逻辑
           if ("myValidator".equals(s))
               return true;
           return false;
       }
   }
   ~~~

   

3. 所有自定义注解

   ~~~java
   @MyChecker
   private String name;
    
    
   ~~~

   

---

### 日志管理

1. 本地日志打印控制台
2. 服务器日志可以通过admin页面查询在线日志，在线日志循环输出，默认保留10M大小，系统中配置了ELK所以可以直接在kibana上面看
3. 服务器日志所有DailyFileAppender 和**KafkaAppender**，系统配置的是kafka来收集
4. 在容器平台部署的服务，推荐使用kafkaAppender，日志最终会保存在elasticsearch中，通过kibana提供日志的查询。虚拟机部署的应用可以使用DailyFileAppender
4. **大致逻辑**：自定义KafkaAppender 继承自AppenderBase\<E>，配置kafka消息，单独起线程去把日志写入到一个队列里面，把队列里面的数据写入到kafka

#### KafkaAppender的使用

修改logback-spring.xml

~~~xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include
        resource="org/springframework/boot/logging/logback/base.xml" />
    <jmxConfigurator />
 
     
    <appender name="kafkaAppender"
        class="com.qc.kafka.appender.KafkaAppender">
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd
                HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:-
                }){magenta} %clr(---){faint} %clr([%15.15t]){faint}
                %clr(%-40.40logger{39}){cyan} %clr(:){faint}
                %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}</pattern>
        </encoder>
         
    </appender>
 
    <logger name="com.qc.kafka">
        <appender-ref ref="kafkaAppender" /> 如果只需要部分数据出现在日志中，则配置指定相应的包，不需要配置root appender
    </logger>
 
    <root>
        <appender-ref ref="kafkaAppender" /> 这里配置，代表所有日志都需要发送kafka
    </root>
</configuration>
~~~





专门开发一个服务来管理日志：例如sys-log

sys-log工程收集kafka中的系统日志，（应该有一层logstash进行聚合以及数据处理后）并发送到elasticsearch工程（进行分词、创建索引并存储），最终由Kibana搜寻es后进行展示，还会监控网关的用户访问日志

根据日期生成日志，方便搜索，问题排查



#### 代码中日志的使用

lombok方式 @Slf4j注解

~~~java
log.debug();
log.info();
~~~

---



### 代码生成器

mybatis-plus  逆向工程

---

### 数据库设计规范

设计过程：逻辑数据模型设计、物理数据库设计、实现数据库三个步骤，可通过powerDesigner工具进行

按照业务模块分别构建数据库模型（ER图），进行物理数据库设计，完成后生成数据字典，生成相应数据库的DDL脚本，创建特定DBMS的数据库对象



---

### 作业调度子系统

![image-20220919150726392](../AppData/Roaming/Typora/typora-user-images/image-20220919150726392.png)

作业管理与监控

![image-20220919145440934](../AppData/Roaming/Typora/typora-user-images/image-20220919145440934.png)

![image-20220919145333887](../AppData/Roaming/Typora/typora-user-images/image-20220919145333887.png)





---

### 缓存

SpringCache只是提供了基本的Cache抽象，并没有具体的缓存能力，需要配合具体的缓存实现来完成。底层可以通过CacheManager接口来统一切换不同的缓存技术。Cache接口下Spring提供了各种xxxCache的实现，例如：RedisCache、EhCache、ConcurrentMapChae。SpringCache默认是使用ConcurrentMapCache来进行数据的缓存



**项目采用了**SpringCache+Redis实现的缓存，通过使用注解的方式，自动添加缓存到redis中

参考实例：https://blog.csdn.net/user2025/article/details/106595257



spring cache的缓存注解

1. @Cacheable：触发缓存写入
2. @CacheEvict：触发缓存清除
3. @CachePut：更新缓存(不会影响方法的运行)
4. @Caching：重新组合要应用于方法的多个缓存操作



通常强烈建议不要对同一方法同时使用@CachePut和@Cacheable注解，因为它们具有不同的行为。可能会产生不可思议的BUG哦。



如何实现：

1. 通过继承CachingConfigurerSupport类自定义缓存管理器实现：**项目中采用的这种方式**
2. 通过RedisCacheConfiguration.defaultCacheConfig()获取到默认的RedisCacheConfiguration对象。修改RedisCacheConfiguration对象的序列化方式等参数
   - 结合-配置文件配置的方式：个人感觉有点死板
   - 并且：在缓存配置类中配置以后，yaml配置文件中关于缓存的redis配置就不会生效，如果需要相关配置需要通过@value去读取





使用SpringCache缓存抽象时，需要注意以下两点

1. 确定方法需要被缓存以及它们的缓存策略
2. 从缓存中读取之前缓存存储的数据

---



### 单元测试

Mock、覆盖率、sonar

技术：TestContainers+Dbunit(注解+自定义excel测试文件，dbunit那一套进行修改了些 已适用于自己的场景)+Mock框架(自己也做了相应的修改)+断言(测试结果必须断言)

单元测试要求

1. 对接口api层进行测试，覆盖率要达到80%
2. 业务代码的处理逻辑准备测试用例，拿着测试用例进行单元测试
3. 单元测试中，针对依赖的外部服务接口Mock，这样保证单元测试的稳定性。并且在测试环境中不会连接注册服务器，因此无法调用feign的服务接口

单元测试架构

1. 采用docker镜像方式
2. 代码中需要的redis、kafka、es、数据库等等采用docker镜像方式在单元测试启动的时候启动，单元测试停止时关闭
3. 针对数据库数据，每个测试方法提前准备好测试数据，xlsx文件（数据文件）
4. 对于hdfs问题，提供本地模拟的hdfs接口，从而不影响测试代码的执行

架构提供的：单元测试启动的时候，会准备一个虚拟的web环境，测试代码中，可以访问web中的url（api）

#### TestContainers

是一个开源项目，它提供可以在Docker容器中运行的任何东西的轻量级，一次性的实例。它具有Java，Python，Rust，Go，Scala和许多其他语言的绑定。其主要针对**测试领域**、背靠Docker实现**环境百宝箱**功能

 简单理解就是，testcontainers 能够让你实现通过编程语言去启动Docker容器，并在程序测试结束后，自动关闭容器。这基本上能解决我们大部分的需求

1. 基于Docker
2. testContainers提供的环境不能应用于生产环境，只能用于测试等场景
3. Testcontainers 提供了多种现成的与测试关联的应用程序容器
4. 不同语言版本的testContainers

##### 数据访问层集成

 使用MySQL，PostgreSQL或Oracle数据库的容器化实例测试您的数据访问层代码是否具有完全兼容性，但无需在开发人员的计算机上进行复杂的设置，并且无需担心测试始终以已知的数据库状态。 也可以使用任何其他可以容器化的数据库类型。



---

### 接口管理

swagger、eolinker



---

### 代码质量

1. checkstyle插件
2. sonar

---



### 微服务架构

#### 访问控制管理

前端页面部署在nginx上，通过写cookie的方式使多个前台项目共享token，达到单点登录效果。前台访问后台采用自定义的加密格式。网关统一验证url、token、时间戳

![image-20220525163717494](https://pic-typora-qc.oss-cn-chengdu.aliyuncs.com/company_img/202205251637761.png)



login成功后，返回token；前端访问后端时，需要在header中添加Authorization，ApiKeys字段

header ：Apikeys字段，这个是验证的核心字段，它是一个加密的Json串，由三部分组成

1. url：这次访问的url
2. timestamp：本次访问的时间戳
3. token：本次访问authorization字段中使用的token

此json字符串使用AES(AES/CBC/PKCS5Padding)加密，密钥为authorization中tokent的后16位字符

网关验证Apikeys：

1. tokent必须正确
2. ApiKeys中解析出来的url与访问的url一致，防止有人越权修改url参数来访问
3. timestamp必须在10分钟之内，防止过期的Apikeys访问





---

#### Nacos



##### 灰度发布与权重：项目中应用

灰度发布：



前端传递一个：app-version字段

应用端配置：

~~~yaml
spring:
  application:
    version: 0.1.1
~~~



Nacos页面上配置该服务元数据：

~~~json
{

  "startup.time": "2022-11-21 12:31:00",

  "preserved.register.source": "SPRING_CLOUD",

  "version": "DEFAULT"    该字段可用于是否用于灰度发布

}
~~~



1. 应用端如果需要不同版本的发布，可以设置上面的配置，设置对应的版本，则请求发送到对应版本的实例上
2. 如果应用不设置版本，则请求将可能被发送到所有节点



自定义Nacos  IRule规则、按照是否配置该字段，并且通过权重来选择实例







---



#### Gateway

系统采用

采用【自动发现】+【自定义网关】组合实现，gateway路由匹配原理参考nginx（访问url在匹配到对应的路由后即停止）

网关匹配顺序配置了响应的order，自动发现路由order默认为0，自定义网关order根据需要调整



##### 负载均衡

默认全局采用轮询规则：RoundRobinRule

##### 访问控制

1. 默认对所有请求进行拦截，统一调用单点登录访问API进行校验，即：上面访问控制管理

2. 不需要拦截的请求可以进行过滤

   ~~~yml
   access:
     filters:
       - /xxx
   ~~~

##### 限流

所有gateway自带的令牌桶算法 filter

~~~yml
spring:
  application:
    name: gateway
  cloud:        # spring cloud gateway 路由配置方式
    gateway:
      discovery:
        locator:
          enabled: true
          lowerCaseServiceId: true
      routes:
        - id:  
          uri:  lb://xxxx     负载均衡
          order: -1
          predicates:
            - Path=/**
          filters:
            - StripPrefix=1
            - name: RequestRateLimiter               gateway默认采用了Redis的令牌桶限流算法
              args:
                key-resolver: "#{@ipKeyResolver}"
                redis-rate-limiter.replenishRate: 1
                redis-rate-limiter.burstCapacity: 1
        
~~~



---

### 系统设计规范与原则

#### redis的使用

系统中默认的redis客户端为redisson，redisson启动默认使用了连接池

##### 典型使用场景

1. k-v缓存

2. 分布式计数器

3. 分布式锁

4. 取最新N个值

5. 使用key的过期时间

6. 布隆过滤器

   - Redis中有一个数据结构叫做Bitmap(下方有官网详解)，它提供一个最大长度为512MB（2^32）的位数组。我们可以把它提供给布隆过滤器做位数组。根据《数学之美》中给出的数据，在使用8个哈希函数的情况下，512MB大小的位数组在误报率万分之五的情况下可以对约两亿的url去重。而若单纯的使用set()去重的话，以一个url64个字节记，两亿url约需要128GB的内存空间,不敢想象
   - kafka消息采用了此方法去重

7. 延迟处理消息

   - 基于redis可以实现延迟队列。例如有些业务场景，当发生业务数据时，需要记录，并规定在指定时间之后，才做处理。则可以使用下面的处理方法

   - ~~~java
     @Autowired
     private  DelayQueue delayQueue;  
      
     @Test
     public void testDelay() throws InterruptedException {
         String message = "delay message";
      
         delayQueue.addQueue(message, 10, TimeUnit.SECONDS);
         log.info("发送延迟消息,  time = {}", new Date());
      
         delayQueue.processEvent(String.class, (t) -> {
             log.info("收到了延迟消息 ,message = {}, time = {}", t, new Date());
         });
      
         Thread.sleep(30000l);
     }
     ~~~

     ---



#### 发布订阅设计结合Kafka

kafka配置了四个分区

发布订阅+补偿

---



#### 分布式事务

采用Seata 

注意事项：

1. 业务表中必须包含单列主键 。
2. 每个业务库中必须包含 undo_log 表，若与分库分表组件联用，分库不分表。
3. 目前AT模式支持的数据库有：MySQL、Oracle、PostgreSQL和 TiDB。
4. 使用注解开启分布式事务时，若默认服务 provider 端加入 consumer 端的事务，provider 可不标注注解。但是，provider 同样需要相应的依赖和配置，仅可省略注解。
5. 使用注解开启分布式事务时，若要求事务回滚，必须将异常抛出到事务的发起方，被事务发起方的 @GlobalTransactional 注解感知到。provide 直接抛出异常 或 定义错误码由 consumer 判断再抛出异常。
6.  @Transactional 需要在 @GlobalTransactional  方法里



#### 分库分表

单表行数超过500w，或单表容量超过2G，推荐分库分布。若预计3年后的数据量达不到这个级别则不建议创建的时候分库分表

Apache ShardingJDBC



配置文件案例

~~~properties
spring.shardingsphere.datasource.names=ds0,ds1
 
spring.shardingsphere.datasource.ds0.type=org.apache.commons.dbcp.BasicDataSource
spring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds0.url=jdbc:mysql://localhost:3306/ds0
spring.shardingsphere.datasource.ds0.username=root
spring.shardingsphere.datasource.ds0.password=
 
spring.shardingsphere.datasource.ds1.type=org.apache.commons.dbcp.BasicDataSource
spring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds1.url=jdbc:mysql://localhost:3306/ds1
spring.shardingsphere.datasource.ds1.username=root
spring.shardingsphere.datasource.ds1.password=
 
spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds$->{0..1}.t_order$->{0..1}
spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id
spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order$->{order_id % 2}
spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id
spring.shardingsphere.sharding.tables.t_order_item.actual-data-nodes=ds$->{0..1}.t_order_item$->{0..1}
spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKE
spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.sharding-column=order_id
spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.algorithm-expression=t_order_item$->{order_id % 2}
spring.shardingsphere.sharding.tables.t_order_item.key-generator.column=order_item_id
spring.shardingsphere.sharding.tables.t_order_item.key-generator.type=SNOWFLAKE
spring.shardingsphere.sharding.binding-tables=t_order,t_order_item
spring.shardingsphere.sharding.broadcast-tables=t_config
 
spring.shardingsphere.sharding.default-database-strategy.inline.sharding-column=user_id
spring.shardingsphere.sharding.default-database-strategy.inline.algorithm-expression=ds$->{user_id % 2}
~~~

---

#### OCR图片识别

接入阿里的接口

---

#### 预警设计

自动监控发送到kafka的日志数据

---















---



### 项目用到的东西

数据库：oracle、GP、MySQL

开发：ssm+springboot+cloud

链路追踪：sleuth(乱路追踪器)+zipkin(链路分析器 可视化的）+kafka

- 分布式链路追踪：**（Distributed Tracing）**，就是将一次分布式请求还原成调用链路，进行日志记录，性能监控并将一次分布式请求的调用情况集中展示。比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等
- seluth：日志记录每一条链路上的所有节点，以及这些节点所在的机器，和耗时

分页：mybatis、mybatis-plus、springdata分页

批量：springbatch

日志：logback+kafka+logstash+ES+Kibana

job：quartz+kafka

接口管理：swagger、eolinker

分布式文件系统：hdfs

分布式事务：seata

中间件：redis、对应客户端redisson

发布订阅：kafka

部署：docker、k8s、openshift、jenkins

权限、验证：Spring Security+OAuth2+JWT





#### SpringBoot启动

启动类的引导类继承自一个配置类，该配置类设置时区、Swagger2文档、国际化、CorsFilter跨域、验证器等操作

#### Serice架构

service：可以继承一个抽象Service，该Service封装mybatisplus的相关操作

例如

1. 添加一个实体进数据库add：采用雪花算法计算sequence(id)，调用basemapper的insert
2. 批量插入：forEach操作add
3. 添加、更新等操作可以预留一个操作entity的受保护方法，例如：雪花算法生成seq就是在之前对entity进行的操作
4. 等等一些列操作
5. 分页：根据spring的分页，转换为mybatis的分页组件
6. wrapper的处理、sql的处理等等
7. 指的学习！！



#### 全局异常处理

RestFulApiExceptionHandler 

@ControllerAdvice+@ExceptionHandler（）：同一处理方法抛出的异常，可以指定某一类的异常来进行处理

封装进返回体，异常消息发送kafka，进行监控





#### 数据源切换

注解方式+aop切入service，实现动态切换数据源

注意：实现数据源持有类ThreadLocal，保证线程隔离

使用：在service上添加注解即可

---

#### 项目监控

SpringBoot应用监控常见方案

应用监控需要哪些东西？

1. 信息采集器
2. 数据可视化

方案：

1. SpringBoot Actuator+SpringBoot Admin
   - Actuator采集数据，Admin展示
2. promethues+Grafana 
   - promethues数据获取（自己也有UI不过用户体验不行），在Grafana中展示
   - 微服务中此种方式更为推荐，项目也是采用这种方式

---





#### 发送短信

申请阿里云的短信模板、备案





### 部署

openshift：基于k8s

#### 镜像

Quay项目：RedHat开源镜像项目

Quay是一个registry，存储、构建、部署容器的分布式高可用容器镜像仓库



openshift+Quay镜像部署





---

### Kafka





